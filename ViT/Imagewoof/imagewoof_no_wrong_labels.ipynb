{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f71001d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74c727ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/zo2151/imagenette/noisy_imagewoof.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20d6bc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.iloc[:9469,:2]\n",
    "df_test = df.iloc[9469:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d9d61a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"/home/zo2151/imagewoof2-160/train/train.csv\")\n",
    "df_test.to_csv(\"/home/zo2151/imagewoof2-160/val/val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7784bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptrain = []\n",
    "ltrain = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c37143a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9469):\n",
    "    filename = '/home/zo2151/imagewoof2-160/'+df.iloc[i,0]\n",
    "    filename1 = filename[:-4]\n",
    "    filename1 = filename1 + \"jpeg\"\n",
    "    os.rename(filename, filename1)\n",
    "    ptrain.append(filename1)\n",
    "    ltrain.append(df.iloc[i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be10175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pval = []\n",
    "lval = []\n",
    "for i in range(9469,df.shape[0]):\n",
    "    filename = '/home/zo2151/imagewoof2-160/'+df.iloc[i,0]\n",
    "    filename1 = filename[:-4]\n",
    "    filename1 = filename1 + \"jpeg\"\n",
    "    os.rename(filename, filename1)\n",
    "    pval.append(filename1)\n",
    "    lval.append(df.iloc[i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4375a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification, TrainingArguments, Trainer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import (CenterCrop, \n",
    "                                    Compose, \n",
    "                                    Normalize, \n",
    "                                    RandomHorizontalFlip,\n",
    "                                    RandomResizedCrop, \n",
    "                                    Resize, \n",
    "                                    ToTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e761e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c2f6341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28fff0b6504b4593bceb275b22b55f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/9469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration train-e6f06bbfc2b8d6c5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset image_folder/train to /home/zo2151/.cache/huggingface/datasets/image_folder/train-e6f06bbfc2b8d6c5/0.0.0/ee92df8e96c6907f3c851a987be3fd03d4b93b247e727b69a8e23ac94392a091...\n",
      "                "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed33178184bb46e0b141c315e93f2c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #0:   0%|          | 0/592 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f0ed5a71974b8db7a2941a0fb03010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #6:   0%|          | 0/592 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d305c214dc064fd5a43aef2c6029c25c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #2:   0%|          | 0/592 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d14d283d3e8b455ba2e5d82904ffc663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #12:   0%|          | 0/592 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3913fe639334965b81a561915f6ccd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #9:   0%|          | 0/592 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f5f9b2641424deda22b00236fecdaa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #11:   0%|          | 0/592 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc8e21f119347da9398d77159e7dc59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #8:   0%|          | 0/592 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b2c74a1f4d45568890b9a73955ee91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #1:   0%|          | 0/592 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587fd89ac6ec44d0a51f6ed4a1b199ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #10:   0%|          | 0/592 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434a47bfaabd4d578949fc4bd969f56d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #5:   0%|          | 0/592 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b2ced8d92348f9b359ad9994567f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #3:   0%|          | 0/592 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49e36ac1e9d4264b8e6637a63689ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #14:   0%|          | 0/591 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc735181af94491b28b64d079005bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #15:   0%|          | 0/591 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6592d86a9e40e1847dce4bc1254ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #4:   0%|          | 0/592 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26780f7af82941099f199b46d19b9ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #13:   0%|          | 0/591 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6882113a0a8408399bb17c0b84eb6dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #7:   0%|          | 0/592 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaaa860d714445f6a9e0598deb0e0c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77493ae800a44b098745eeceb943574f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset image_folder downloaded and prepared to /home/zo2151/.cache/huggingface/datasets/image_folder/train-e6f06bbfc2b8d6c5/0.0.0/ee92df8e96c6907f3c851a987be3fd03d4b93b247e727b69a8e23ac94392a091. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515ce2877fae43689c5b3c2ab99a7be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainset = load_dataset(path = \"/home/zo2151/imagewoof2-160/train\", data_files = ptrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8d6bc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading feature extractor configuration file https://huggingface.co/google/vit-base-patch16-224-in21k/resolve/main/preprocessor_config.json from cache at /home/zo2151/.cache/huggingface/transformers/7c7f3e780b30eeeacd3962294e5154788caa6d9aa555ed6d5c2f0d2c485eba18.c322cbf30b69973d5aae6c0866f5cba198b5fe51a2fe259d2a506827ec6274bc\n",
      "Feature extractor ViTFeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"feature_extractor_type\": \"ViTFeatureExtractor\",\n",
      "  \"image_mean\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ],\n",
      "  \"image_std\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ],\n",
      "  \"resample\": 2,\n",
      "  \"size\": 224\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77fb3e782ab243a69afb7ef21e1b0762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/9469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration train-e6f06bbfc2b8d6c5\n",
      "Reusing dataset image_folder (/home/zo2151/.cache/huggingface/datasets/image_folder/train-e6f06bbfc2b8d6c5/0.0.0/ee92df8e96c6907f3c851a987be3fd03d4b93b247e727b69a8e23ac94392a091)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ec610fa7294402bdcd4ce3a22d1fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833b64ffa7d940dcbf7bd1863b90693f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/3485 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration val-c2a0cca0a61745c6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset image_folder/val to /home/zo2151/.cache/huggingface/datasets/image_folder/val-c2a0cca0a61745c6/0.0.0/ee92df8e96c6907f3c851a987be3fd03d4b93b247e727b69a8e23ac94392a091...\n",
      "                "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb420b9575f2437fab216ede6ea9e731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #1:   0%|          | 0/218 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8cc850607884777981ae2d229a34228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #8:   0%|          | 0/218 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9d4a0f25824bfc88662715b3a70d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #0:   0%|          | 0/218 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56cc37d6942412f92107106a33a9bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #4:   0%|          | 0/218 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d643516ca6e948c6bb9d2592eedea07d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #9:   0%|          | 0/218 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bda940ef0054496861b58ac0c9d87f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #10:   0%|          | 0/218 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8ed50c4f5d40cab4a6a8875058de3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #6:   0%|          | 0/218 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd380ac233124f95aa8f1af2ebc12430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #13:   0%|          | 0/217 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af17878acfa5468088b813316eec2051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #15:   0%|          | 0/217 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa3032d4371c4b2a8779e3c3dbd70bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #12:   0%|          | 0/218 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0d578aeb0445929c084b91ae565830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #11:   0%|          | 0/218 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f836c70a0c541c9ad7a906c26436eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #2:   0%|          | 0/218 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9223736409eb43d28184704b8f620f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #3:   0%|          | 0/218 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0fe76d9bfe7481cbec18868d292c0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #7:   0%|          | 0/218 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428e4b142c294c078114850a0df05e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #14:   0%|          | 0/217 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1fa5218a0634e34a88954ca3806abad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files #5:   0%|          | 0/218 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86129c013ed140ce9e617a4c2e0b7ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b843fc01d99b4dc7adca8adb363c153f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset image_folder downloaded and prepared to /home/zo2151/.cache/huggingface/datasets/image_folder/val-c2a0cca0a61745c6/0.0.0/ee92df8e96c6907f3c851a987be3fd03d4b93b247e727b69a8e23ac94392a091. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52cd71625d824df5b800d002a434d194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "_train_transforms = Compose(\n",
    "        [\n",
    "            RandomResizedCrop(feature_extractor.size),\n",
    "            RandomHorizontalFlip(),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "_val_transforms = Compose(\n",
    "        [\n",
    "            Resize(feature_extractor.size),\n",
    "            CenterCrop(feature_extractor.size),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "trainset = load_dataset(path = \"/home/zo2151/imagewoof2-160/train\", data_files = ptrain)\n",
    "valset = load_dataset(path = \"/home/zo2151/imagewoof2-160/val\", data_files = pval)\n",
    "def train_transforms(examples):\n",
    "    examples['pixel_values'] = [_train_transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
    "    return examples\n",
    "\n",
    "def val_transforms(examples):\n",
    "    examples['pixel_values'] = [_val_transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
    "    return examples\n",
    "\n",
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad1e4ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset1 = trainset[\"train\"]\n",
    "test_ds = valset[\"train\"]\n",
    "splits = trainset1.train_test_split(test_size=0.1)\n",
    "train_ds = splits['train']\n",
    "val_ds = splits['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cd78b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.set_transform(train_transforms)\n",
    "val_ds.set_transform(val_transforms)\n",
    "test_ds.set_transform(val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e47c3b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d757e82e36d4dafafe5a29cacc31828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/502 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6243c8bd3860456fb3d63d03edfd3981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/330M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k',\n",
    "                                                  num_labels=10,\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44c70e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 8522\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 402\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='402' max='402' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [402/402 02:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.911594</td>\n",
       "      <td>0.868004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.655182</td>\n",
       "      <td>0.893347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.597861</td>\n",
       "      <td>0.909187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 947\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to test-cifar-10/checkpoint-134\n",
      "Configuration saved in test-cifar-10/checkpoint-134/config.json\n",
      "Model weights saved in test-cifar-10/checkpoint-134/pytorch_model.bin\n",
      "Feature extractor saved in test-cifar-10/checkpoint-134/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 947\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to test-cifar-10/checkpoint-268\n",
      "Configuration saved in test-cifar-10/checkpoint-268/config.json\n",
      "Model weights saved in test-cifar-10/checkpoint-268/pytorch_model.bin\n",
      "Feature extractor saved in test-cifar-10/checkpoint-268/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 947\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to test-cifar-10/checkpoint-402\n",
      "Configuration saved in test-cifar-10/checkpoint-402/config.json\n",
      "Model weights saved in test-cifar-10/checkpoint-402/pytorch_model.bin\n",
      "Feature extractor saved in test-cifar-10/checkpoint-402/preprocessor_config.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from test-cifar-10/checkpoint-402 (score: 0.9091869060190074).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=402, training_loss=1.0392827275973648, metrics={'train_runtime': 153.6405, 'train_samples_per_second': 166.401, 'train_steps_per_second': 2.616, 'total_flos': 1.9813022585849364e+18, 'train_loss': 1.0392827275973648, 'epoch': 3.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_name = \"accuracy\"\n",
    "args = TrainingArguments(\n",
    "    f\"test-cifar-10\",\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    logging_dir='logs',\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "metric = load_metric(metric_name)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=feature_extractor,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "251c8b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 3485\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='55' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [55/55 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.6187190413475037, 'test_accuracy': 0.9073170731707317, 'test_runtime': 11.9855, 'test_samples_per_second': 290.769, 'test_steps_per_second': 4.589}\n"
     ]
    }
   ],
   "source": [
    "outputs = trainer.predict(test_ds)\n",
    "print(outputs.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e08202a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
