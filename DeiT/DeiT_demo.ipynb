{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd9a87c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import DeiTModel, DeiTFeatureExtractor, DeiTForImageClassification, TrainingArguments, Trainer\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torchvision.transforms import (CenterCrop, \n",
    "                                    Compose, \n",
    "                                    Normalize, \n",
    "                                    RandomHorizontalFlip,\n",
    "                                    RandomResizedCrop, \n",
    "                                    Resize, \n",
    "                                    ToTensor)\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "from timm.data import Mixup\n",
    "from timm.models import create_model\n",
    "from timm.optim import create_optimizer\n",
    "from timm.utils import ModelEma, NativeScaler, get_state_dict\n",
    "from timm.scheduler import create_scheduler\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "from PIL import Image\n",
    "from losses import DistillationLoss\n",
    "from pathlib import Path\n",
    "from engine import train_one_epoch, evaluate\n",
    "import time\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets.folder import ImageFolder, default_loader\n",
    "from timm.data import create_transform\n",
    "import os\n",
    "import utils\n",
    "import json\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71861e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('./DeiT/out_imgnet/checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10bc9094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acdf2a0a63104c1d8db045a3319759ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ./data\n",
       "    Split: Train"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.CIFAR10('./data', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5977f730",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_path = './data'\n",
    "imgnet_path = '/home/ecbm4040/.cache/huggingface/datasets/downloads/extracted/0201c2598c4cf28a3ea355e57a1b281d33183822b6848bd3c1ea3285835cb028/ILSVRC/Data/CLS-LOC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a055a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class build_args():\n",
    "    def __init__(self, \n",
    "                 epochs=1,\n",
    "                 batch_size=256,\n",
    "                 input_size=224, color_jitter=0.4, \n",
    "                 aa='rand-m9-mstd0.5-inc1', train_interpolation='bicubic', \n",
    "                 reprob=0.25, remode='pixel', recount=1,\n",
    "                 distributed=False, distillation_type='none',\n",
    "                 device='cuda', seed=0, finetune='', eval_mode=False,\n",
    "                 data_set='IMNET', data_path = './data', num_workers=4, pin_mem=True,\n",
    "                 mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0,\n",
    "                 mixup_switch_prob=0.5, mixup_mode='batch', smoothing=0.1,\n",
    "                 model='deit_tiny_patch16_224', drop=0.0, drop_path=0.1,\n",
    "                 model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False,\n",
    "                 sched='cosine', lr=5e-4, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0,\n",
    "                 warmup_lr=1e-6, min_lr=1e-5, opt='adamw', opt_eps=1e-8, opt_betas=None,\n",
    "                 clip_grad=None, momentum=0.9, weight_decay=0.05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10,\n",
    "                 teacher_model='regnety_160', teacher_path='', output_dir='./deit_output', resume='',\n",
    "                 distillation_alpha=0.5, distillation_tau=1.0):\n",
    "        \n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.output_dir = output_dir\n",
    "        self.resume = resume\n",
    "        self.start_epoch=0\n",
    "        \n",
    "        # model\n",
    "        self.input_size = input_size\n",
    "        self.model = model\n",
    "        self.finetune = finetune\n",
    "        self.drop = drop\n",
    "        self.drop_path = drop_path\n",
    "        self.model_ema = model_ema\n",
    "        self.model_ema_decay = model_ema_decay\n",
    "        self.model_ema_force_cpu = model_ema_force_cpu\n",
    "        \n",
    "        # optimizer\n",
    "        self.opt = opt\n",
    "        self.opt_eps = opt_eps\n",
    "        self.opt_betas = opt_betas\n",
    "        self.clip_grad = clip_grad\n",
    "        self.momentum = momentum\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "        # augmentation\n",
    "        self.color_jitter = color_jitter\n",
    "        self.aa = aa\n",
    "        self.train_interpolation = train_interpolation\n",
    "        self.smoothing = smoothing\n",
    "        self.reprob = reprob\n",
    "        self.remode = remode\n",
    "        self.recount = recount\n",
    "        self.distributed = distributed\n",
    "        self.distillation_type = distillation_type\n",
    "        self.device = device\n",
    "        self.seed = seed\n",
    "        self.eval = eval_mode\n",
    "        self.data_set = data_set\n",
    "        self.data_path = data_path\n",
    "        self.num_workers = num_workers\n",
    "        self.pin_mem = pin_mem\n",
    "        self.nb_classes = 0\n",
    "        \n",
    "        # mixup\n",
    "        self.mixup = mixup\n",
    "        self.cutmix = cutmix\n",
    "        self.cutmix_minmax = cutmix_minmax\n",
    "        self.mixup_prob = mixup_prob\n",
    "        self.mixup_switch_prob = mixup_switch_prob\n",
    "        self.mixup_mode = mixup_mode\n",
    "        \n",
    "        # learning rate schedule\n",
    "        self.sched = sched\n",
    "        self.lr = lr\n",
    "        self.lr_noise = lr_noise\n",
    "        self.lr_noise_pct = lr_noise_pct\n",
    "        self.lr_noise_std = lr_noise_std\n",
    "        self.warmup_lr = warmup_lr\n",
    "        self.min_lr = min_lr\n",
    "        self.decay_epochs = 30\n",
    "        self.warmup_epochs = 5\n",
    "        self.cooldown_epochs = 10\n",
    "        \n",
    "        # distillation\n",
    "        self.teacher_model = teacher_model\n",
    "        self.teacher_path = teacher_path\n",
    "        self.distillation_alpha = distillation_alpha\n",
    "        self.distillation_tau = distillation_tau\n",
    "    \n",
    "args = build_args(data_set='IMNET', data_path=imgnet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a038a20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.distillation_type != 'none' and args.finetune and not args.eval:\n",
    "    raise NotImplementedError(\"Finetuning with distillation not yet supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "597dd7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56eb9b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the seed for reproducibility\n",
    "seed = args.seed\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bd5e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input do not change, set cuda to find best algorithm\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2da5a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transform(is_train, args):\n",
    "    resize_im = args.input_size > 32\n",
    "    if is_train:\n",
    "        # this should always dispatch to transforms_imagenet_train\n",
    "        transform = create_transform(\n",
    "            input_size=args.input_size,\n",
    "            is_training=True,\n",
    "            color_jitter=args.color_jitter,\n",
    "            auto_augment=args.aa,\n",
    "            interpolation=args.train_interpolation,\n",
    "            re_prob=args.reprob,\n",
    "            re_mode=args.remode,\n",
    "            re_count=args.recount,\n",
    "        )\n",
    "        if not resize_im:\n",
    "            # replace RandomResizedCropAndInterpolation with\n",
    "            # RandomCrop\n",
    "            transform.transforms[0] = transforms.RandomCrop(\n",
    "                args.input_size, padding=4)\n",
    "        return transform\n",
    "\n",
    "    t = []\n",
    "    if resize_im:\n",
    "        size = int((256 / 224) * args.input_size)\n",
    "        t.append(\n",
    "            transforms.Resize(size, interpolation=transforms.InterpolationMode.BICUBIC),  # to maintain same ratio w.r.t. 224 images\n",
    "        )\n",
    "        t.append(transforms.CenterCrop(args.input_size))\n",
    "\n",
    "    t.append(transforms.ToTensor())\n",
    "    t.append(transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD))\n",
    "    return transforms.Compose(t)\n",
    "\n",
    "def build_dataset(is_train, args):\n",
    "    transform = build_transform(is_train, args)\n",
    "\n",
    "    if args.data_set == 'CIFAR':\n",
    "        dataset = datasets.CIFAR100(args.data_path, train=is_train, transform=transform)\n",
    "        nb_classes = 100\n",
    "    elif args.data_set == 'IMNET':\n",
    "        root = os.path.join(args.data_path, 'train' if is_train else 'val')\n",
    "        dataset = datasets.ImageFolder(root, transform=transform)\n",
    "        nb_classes = 1000\n",
    "\n",
    "    return dataset, nb_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81e9141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "60efffb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, args.nb_classes = build_dataset(is_train=True, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b0f0e7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val, _ = build_dataset(is_train=False, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "85c353a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_train = torch.utils.data.RandomSampler(dataset_train)\n",
    "sampler_val = torch.utils.data.SequentialSampler(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1915b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "    dataset_train, sampler=sampler_train,\n",
    "    batch_size=args.batch_size,\n",
    "    num_workers=args.num_workers,\n",
    "    pin_memory=args.pin_mem,\n",
    "    drop_last=True,\n",
    "    )\n",
    "\n",
    "data_loader_val = torch.utils.data.DataLoader(\n",
    "    dataset_val, sampler=sampler_val,\n",
    "    batch_size=int(1.5 * args.batch_size),\n",
    "    num_workers=args.num_workers,\n",
    "    pin_memory=args.pin_mem,\n",
    "    drop_last=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76b7ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use mixup strategy\n",
    "mixup_fn = None\n",
    "mixup_active = args.mixup > 0 or args.cutmix > 0. or args.cutmix_minmax is not None\n",
    "if mixup_active:\n",
    "    mixup_fn = Mixup(\n",
    "        mixup_alpha=args.mixup, cutmix_alpha=args.cutmix, cutmix_minmax=args.cutmix_minmax,\n",
    "        prob=args.mixup_prob, switch_prob=args.mixup_switch_prob, mode=args.mixup_mode,\n",
    "        label_smoothing=args.smoothing, num_classes=args.nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e562b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model: deit_tiny_patch16_224\n"
     ]
    }
   ],
   "source": [
    "print(f\"Creating model: {args.model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "866dcf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(\n",
    "        args.model,\n",
    "        pretrained=False,\n",
    "        num_classes=args.nb_classes,\n",
    "        drop_rate=args.drop,\n",
    "        drop_path_rate=args.drop_path,\n",
    "        drop_block_rate=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dc38667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 192, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "  (pre_logits): Identity()\n",
       "  (head): Linear(in_features=192, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8aa38896",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ema = None\n",
    "if args.model_ema:\n",
    "    # Important to create EMA model after cuda(), DP wrapper, and AMP but before SyncBN and DDP wrapper\n",
    "    model_ema = ModelEma(\n",
    "        model,\n",
    "        decay=args.model_ema_decay,\n",
    "        device='cpu' if args.model_ema_force_cpu else '',\n",
    "        resume='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98d66e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_ddp = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58f0ef75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params: 5717416\n"
     ]
    }
   ],
   "source": [
    "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('number of params:', n_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60076a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_scaled_lr = args.lr*args.batch_size/512.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4baff5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.lr = linear_scaled_lr\n",
    "optimizer = create_optimizer(args, model_without_ddp)\n",
    "loss_scaler = NativeScaler()\n",
    "lr_scheduler, _ = create_scheduler(args, optimizer)\n",
    "criterion = LabelSmoothingCrossEntropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bba5fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mixup_active:\n",
    "    # smoothing is handled with mixup label transform\n",
    "    criterion = SoftTargetCrossEntropy()\n",
    "elif args.smoothing:\n",
    "    criterion = LabelSmoothingCrossEntropy(smoothing=args.smoothing)\n",
    "else:\n",
    "    criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0404cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa226ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap the criterion in our custom DistillationLoss, which\n",
    "# just dispatches to the original criterion if args.distillation_type is 'none'\n",
    "criterion = DistillationLoss(\n",
    "    criterion, teacher_model, args.distillation_type, args.distillation_alpha, args.distillation_tau\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e75768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3c2ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.resume:\n",
    "    if args.resume.startswith('https'):\n",
    "        checkpoint = torch.hub.load_state_dict_from_url(\n",
    "            args.resume, map_location='cpu', check_hash=True)\n",
    "    else:\n",
    "        checkpoint = torch.load(args.resume, map_location='cpu')\n",
    "    model_without_ddp.load_state_dict(checkpoint['model'])\n",
    "    if not args.eval and 'optimizer' in checkpoint and 'lr_scheduler' in checkpoint and 'epoch' in checkpoint:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "        args.start_epoch = checkpoint['epoch'] + 1\n",
    "        if args.model_ema:\n",
    "            utils._load_checkpoint_for_ema(model_ema, checkpoint['model_ema'])\n",
    "        if 'scaler' in checkpoint:\n",
    "            loss_scaler.load_state_dict(checkpoint['scaler'])\n",
    "    lr_scheduler.step(args.start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8cebb81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.eval:\n",
    "    test_stats = evaluate(data_loader_val, model, device)\n",
    "    print(f\"Accuracy of the network on the {len(dataset_val)} test images: {test_stats['acc1']:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a54607c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for 1 epochs\n"
     ]
    }
   ],
   "source": [
    "print(f\"Start training for {args.epochs} epochs\")\n",
    "start_time = time.time()\n",
    "max_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ef66c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [   0/5004]  eta: 8:33:41  lr: 0.000001  loss: 6.9520 (6.9520)  time: 6.1593  data: 5.2085  max mem: 6466\n",
      "Epoch: [0]  [  10/5004]  eta: 2:06:21  lr: 0.000001  loss: 6.9459 (6.9437)  time: 1.5181  data: 0.9482  max mem: 6531\n",
      "Epoch: [0]  [  20/5004]  eta: 2:01:50  lr: 0.000001  loss: 6.9392 (6.9441)  time: 1.2322  data: 0.6977  max mem: 6531\n",
      "Epoch: [0]  [  30/5004]  eta: 1:51:58  lr: 0.000001  loss: 6.9392 (6.9437)  time: 1.2587  data: 0.7233  max mem: 6531\n",
      "Epoch: [0]  [  40/5004]  eta: 1:51:35  lr: 0.000001  loss: 6.9395 (6.9423)  time: 1.2249  data: 0.6839  max mem: 6531\n",
      "Epoch: [0]  [  50/5004]  eta: 1:48:28  lr: 0.000001  loss: 6.9395 (6.9428)  time: 1.2568  data: 0.7132  max mem: 6531\n",
      "Epoch: [0]  [  60/5004]  eta: 1:49:25  lr: 0.000001  loss: 6.9431 (6.9433)  time: 1.2852  data: 0.7407  max mem: 6531\n",
      "Epoch: [0]  [  70/5004]  eta: 1:46:15  lr: 0.000001  loss: 6.9451 (6.9436)  time: 1.2364  data: 0.6907  max mem: 6531\n",
      "Epoch: [0]  [  80/5004]  eta: 1:46:38  lr: 0.000001  loss: 6.9421 (6.9428)  time: 1.2127  data: 0.6681  max mem: 6531\n",
      "Epoch: [0]  [  90/5004]  eta: 1:44:19  lr: 0.000001  loss: 6.9358 (6.9432)  time: 1.2095  data: 0.6635  max mem: 6531\n",
      "Epoch: [0]  [ 100/5004]  eta: 1:44:55  lr: 0.000001  loss: 6.9431 (6.9431)  time: 1.2201  data: 0.6723  max mem: 6531\n",
      "Epoch: [0]  [ 110/5004]  eta: 1:43:36  lr: 0.000001  loss: 6.9389 (6.9426)  time: 1.2534  data: 0.7042  max mem: 6531\n",
      "Epoch: [0]  [ 120/5004]  eta: 1:44:11  lr: 0.000001  loss: 6.9313 (6.9422)  time: 1.2605  data: 0.7084  max mem: 6531\n",
      "Epoch: [0]  [ 130/5004]  eta: 1:42:57  lr: 0.000001  loss: 6.9378 (6.9422)  time: 1.2518  data: 0.6973  max mem: 6531\n",
      "Epoch: [0]  [ 140/5004]  eta: 1:43:10  lr: 0.000001  loss: 6.9421 (6.9423)  time: 1.2297  data: 0.6740  max mem: 6531\n",
      "Epoch: [0]  [ 150/5004]  eta: 1:41:44  lr: 0.000001  loss: 6.9377 (6.9420)  time: 1.1938  data: 0.6371  max mem: 6531\n",
      "Epoch: [0]  [ 160/5004]  eta: 1:42:06  lr: 0.000001  loss: 6.9370 (6.9420)  time: 1.2077  data: 0.6487  max mem: 6531\n",
      "Epoch: [0]  [ 170/5004]  eta: 1:40:57  lr: 0.000001  loss: 6.9417 (6.9418)  time: 1.2187  data: 0.6602  max mem: 6531\n",
      "Epoch: [0]  [ 180/5004]  eta: 1:41:13  lr: 0.000001  loss: 6.9444 (6.9416)  time: 1.2129  data: 0.6553  max mem: 6531\n",
      "Epoch: [0]  [ 190/5004]  eta: 1:40:04  lr: 0.000001  loss: 6.9368 (6.9413)  time: 1.1982  data: 0.6394  max mem: 6531\n",
      "Epoch: [0]  [ 200/5004]  eta: 1:40:13  lr: 0.000001  loss: 6.9368 (6.9412)  time: 1.1871  data: 0.6272  max mem: 6531\n",
      "Epoch: [0]  [ 210/5004]  eta: 1:39:26  lr: 0.000001  loss: 6.9361 (6.9408)  time: 1.2182  data: 0.6493  max mem: 6531\n",
      "Epoch: [0]  [ 220/5004]  eta: 1:39:35  lr: 0.000001  loss: 6.9321 (6.9406)  time: 1.2223  data: 0.6497  max mem: 6531\n",
      "Epoch: [0]  [ 230/5004]  eta: 1:38:56  lr: 0.000001  loss: 6.9354 (6.9406)  time: 1.2318  data: 0.6590  max mem: 6531\n",
      "Epoch: [0]  [ 240/5004]  eta: 1:39:20  lr: 0.000001  loss: 6.9316 (6.9404)  time: 1.2744  data: 0.6980  max mem: 6531\n",
      "Epoch: [0]  [ 250/5004]  eta: 1:38:55  lr: 0.000001  loss: 6.9289 (6.9398)  time: 1.3069  data: 0.7263  max mem: 6531\n",
      "Epoch: [0]  [ 260/5004]  eta: 1:39:01  lr: 0.000001  loss: 6.9307 (6.9396)  time: 1.2669  data: 0.6805  max mem: 6531\n",
      "Epoch: [0]  [ 270/5004]  eta: 1:38:18  lr: 0.000001  loss: 6.9370 (6.9395)  time: 1.2142  data: 0.6224  max mem: 6531\n",
      "Epoch: [0]  [ 280/5004]  eta: 1:38:13  lr: 0.000001  loss: 6.9360 (6.9394)  time: 1.1832  data: 0.5926  max mem: 6531\n",
      "Epoch: [0]  [ 290/5004]  eta: 1:37:43  lr: 0.000001  loss: 6.9321 (6.9391)  time: 1.2132  data: 0.6289  max mem: 6531\n",
      "Epoch: [0]  [ 300/5004]  eta: 1:37:53  lr: 0.000001  loss: 6.9346 (6.9388)  time: 1.2641  data: 0.6800  max mem: 6531\n",
      "Epoch: [0]  [ 310/5004]  eta: 1:37:18  lr: 0.000001  loss: 6.9332 (6.9387)  time: 1.2459  data: 0.6638  max mem: 6531\n",
      "Epoch: [0]  [ 320/5004]  eta: 1:37:25  lr: 0.000001  loss: 6.9350 (6.9386)  time: 1.2391  data: 0.6586  max mem: 6531\n",
      "Epoch: [0]  [ 330/5004]  eta: 1:36:45  lr: 0.000001  loss: 6.9355 (6.9385)  time: 1.2155  data: 0.6299  max mem: 6531\n",
      "Epoch: [0]  [ 340/5004]  eta: 1:36:48  lr: 0.000001  loss: 6.9311 (6.9384)  time: 1.2028  data: 0.6161  max mem: 6531\n",
      "Epoch: [0]  [ 350/5004]  eta: 1:36:19  lr: 0.000001  loss: 6.9311 (6.9381)  time: 1.2358  data: 0.6517  max mem: 6531\n",
      "Epoch: [0]  [ 360/5004]  eta: 1:36:18  lr: 0.000001  loss: 6.9305 (6.9378)  time: 1.2243  data: 0.6403  max mem: 6531\n",
      "Epoch: [0]  [ 370/5004]  eta: 1:35:50  lr: 0.000001  loss: 6.9266 (6.9376)  time: 1.2274  data: 0.6444  max mem: 6531\n",
      "Epoch: [0]  [ 380/5004]  eta: 1:35:54  lr: 0.000001  loss: 6.9231 (6.9373)  time: 1.2496  data: 0.6659  max mem: 6531\n",
      "Epoch: [0]  [ 390/5004]  eta: 1:35:19  lr: 0.000001  loss: 6.9283 (6.9371)  time: 1.2131  data: 0.6270  max mem: 6531\n",
      "Epoch: [0]  [ 400/5004]  eta: 1:35:29  lr: 0.000001  loss: 6.9293 (6.9369)  time: 1.2446  data: 0.6591  max mem: 6531\n",
      "Epoch: [0]  [ 410/5004]  eta: 1:35:01  lr: 0.000001  loss: 6.9308 (6.9368)  time: 1.2689  data: 0.6781  max mem: 6531\n",
      "Epoch: [0]  [ 420/5004]  eta: 1:35:01  lr: 0.000001  loss: 6.9320 (6.9368)  time: 1.2284  data: 0.6376  max mem: 6531\n",
      "Epoch: [0]  [ 430/5004]  eta: 1:34:35  lr: 0.000001  loss: 6.9363 (6.9368)  time: 1.2345  data: 0.6496  max mem: 6531\n",
      "Epoch: [0]  [ 440/5004]  eta: 1:34:37  lr: 0.000001  loss: 6.9363 (6.9367)  time: 1.2482  data: 0.6626  max mem: 6531\n",
      "Epoch: [0]  [ 450/5004]  eta: 1:34:12  lr: 0.000001  loss: 6.9355 (6.9367)  time: 1.2503  data: 0.6652  max mem: 6531\n",
      "Epoch: [0]  [ 460/5004]  eta: 1:34:13  lr: 0.000001  loss: 6.9359 (6.9367)  time: 1.2517  data: 0.6614  max mem: 6531\n",
      "Epoch: [0]  [ 470/5004]  eta: 1:33:47  lr: 0.000001  loss: 6.9332 (6.9365)  time: 1.2395  data: 0.6446  max mem: 6531\n",
      "Epoch: [0]  [ 480/5004]  eta: 1:33:45  lr: 0.000001  loss: 6.9303 (6.9365)  time: 1.2231  data: 0.6327  max mem: 6531\n",
      "Epoch: [0]  [ 490/5004]  eta: 1:33:21  lr: 0.000001  loss: 6.9310 (6.9363)  time: 1.2367  data: 0.6489  max mem: 6531\n",
      "Epoch: [0]  [ 500/5004]  eta: 1:33:24  lr: 0.000001  loss: 6.9276 (6.9362)  time: 1.2665  data: 0.6800  max mem: 6531\n",
      "Epoch: [0]  [ 510/5004]  eta: 1:32:56  lr: 0.000001  loss: 6.9286 (6.9361)  time: 1.2381  data: 0.6546  max mem: 6531\n",
      "Epoch: [0]  [ 520/5004]  eta: 1:32:55  lr: 0.000001  loss: 6.9286 (6.9359)  time: 1.2219  data: 0.6387  max mem: 6531\n",
      "Epoch: [0]  [ 530/5004]  eta: 1:32:29  lr: 0.000001  loss: 6.9263 (6.9358)  time: 1.2301  data: 0.6430  max mem: 6531\n",
      "Epoch: [0]  [ 540/5004]  eta: 1:32:20  lr: 0.000001  loss: 6.9231 (6.9356)  time: 1.1786  data: 0.5906  max mem: 6531\n",
      "Epoch: [0]  [ 550/5004]  eta: 1:31:59  lr: 0.000001  loss: 6.9230 (6.9354)  time: 1.2112  data: 0.6156  max mem: 6531\n",
      "Epoch: [0]  [ 560/5004]  eta: 1:31:52  lr: 0.000001  loss: 6.9236 (6.9353)  time: 1.2209  data: 0.6266  max mem: 6531\n",
      "Epoch: [0]  [ 570/5004]  eta: 1:31:24  lr: 0.000001  loss: 6.9240 (6.9351)  time: 1.1713  data: 0.5872  max mem: 6531\n",
      "Epoch: [0]  [ 580/5004]  eta: 1:31:19  lr: 0.000001  loss: 6.9278 (6.9350)  time: 1.1876  data: 0.6002  max mem: 6531\n",
      "Epoch: [0]  [ 590/5004]  eta: 1:30:52  lr: 0.000001  loss: 6.9252 (6.9348)  time: 1.1888  data: 0.6021  max mem: 6531\n",
      "Epoch: [0]  [ 600/5004]  eta: 1:30:50  lr: 0.000001  loss: 6.9252 (6.9349)  time: 1.2127  data: 0.6293  max mem: 6531\n",
      "Epoch: [0]  [ 610/5004]  eta: 1:30:25  lr: 0.000001  loss: 6.9310 (6.9348)  time: 1.2195  data: 0.6350  max mem: 6531\n",
      "Epoch: [0]  [ 620/5004]  eta: 1:30:17  lr: 0.000001  loss: 6.9232 (6.9346)  time: 1.1815  data: 0.5975  max mem: 6531\n",
      "Epoch: [0]  [ 630/5004]  eta: 1:29:52  lr: 0.000001  loss: 6.9212 (6.9343)  time: 1.1755  data: 0.5900  max mem: 6531\n",
      "Epoch: [0]  [ 640/5004]  eta: 1:29:53  lr: 0.000001  loss: 6.9221 (6.9341)  time: 1.2346  data: 0.6453  max mem: 6531\n",
      "Epoch: [0]  [ 650/5004]  eta: 1:29:32  lr: 0.000001  loss: 6.9292 (6.9341)  time: 1.2624  data: 0.6699  max mem: 6531\n",
      "Epoch: [0]  [ 660/5004]  eta: 1:29:27  lr: 0.000001  loss: 6.9293 (6.9340)  time: 1.2271  data: 0.6380  max mem: 6531\n",
      "Epoch: [0]  [ 670/5004]  eta: 1:29:06  lr: 0.000001  loss: 6.9293 (6.9339)  time: 1.2276  data: 0.6416  max mem: 6531\n",
      "Epoch: [0]  [ 680/5004]  eta: 1:28:58  lr: 0.000001  loss: 6.9315 (6.9339)  time: 1.2033  data: 0.6150  max mem: 6531\n",
      "Epoch: [0]  [ 690/5004]  eta: 1:28:36  lr: 0.000001  loss: 6.9282 (6.9338)  time: 1.1925  data: 0.6052  max mem: 6531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [ 700/5004]  eta: 1:28:31  lr: 0.000001  loss: 6.9234 (6.9337)  time: 1.2125  data: 0.6242  max mem: 6531\n",
      "Epoch: [0]  [ 710/5004]  eta: 1:28:12  lr: 0.000001  loss: 6.9264 (6.9336)  time: 1.2319  data: 0.6425  max mem: 6531\n",
      "Epoch: [0]  [ 720/5004]  eta: 1:28:06  lr: 0.000001  loss: 6.9264 (6.9335)  time: 1.2385  data: 0.6512  max mem: 6531\n",
      "Epoch: [0]  [ 730/5004]  eta: 1:27:46  lr: 0.000001  loss: 6.9291 (6.9335)  time: 1.2213  data: 0.6331  max mem: 6531\n",
      "Epoch: [0]  [ 740/5004]  eta: 1:27:42  lr: 0.000001  loss: 6.9287 (6.9334)  time: 1.2327  data: 0.6460  max mem: 6531\n",
      "Epoch: [0]  [ 750/5004]  eta: 1:27:23  lr: 0.000001  loss: 6.9278 (6.9334)  time: 1.2493  data: 0.6641  max mem: 6531\n",
      "Epoch: [0]  [ 760/5004]  eta: 1:27:15  lr: 0.000001  loss: 6.9289 (6.9333)  time: 1.2186  data: 0.6309  max mem: 6531\n",
      "Epoch: [0]  [ 770/5004]  eta: 1:26:57  lr: 0.000001  loss: 6.9266 (6.9332)  time: 1.2185  data: 0.6297  max mem: 6531\n",
      "Epoch: [0]  [ 780/5004]  eta: 1:26:50  lr: 0.000001  loss: 6.9255 (6.9330)  time: 1.2262  data: 0.6386  max mem: 6531\n",
      "Epoch: [0]  [ 790/5004]  eta: 1:26:29  lr: 0.000001  loss: 6.9255 (6.9329)  time: 1.2043  data: 0.6105  max mem: 6531\n",
      "Epoch: [0]  [ 800/5004]  eta: 1:26:23  lr: 0.000001  loss: 6.9299 (6.9329)  time: 1.2182  data: 0.6256  max mem: 6531\n",
      "Epoch: [0]  [ 810/5004]  eta: 1:26:03  lr: 0.000001  loss: 6.9293 (6.9328)  time: 1.2189  data: 0.6326  max mem: 6531\n",
      "Epoch: [0]  [ 820/5004]  eta: 1:25:56  lr: 0.000001  loss: 6.9227 (6.9327)  time: 1.2058  data: 0.6195  max mem: 6531\n",
      "Epoch: [0]  [ 830/5004]  eta: 1:25:36  lr: 0.000001  loss: 6.9234 (6.9326)  time: 1.2035  data: 0.6163  max mem: 6531\n",
      "Epoch: [0]  [ 840/5004]  eta: 1:25:31  lr: 0.000001  loss: 6.9234 (6.9325)  time: 1.2280  data: 0.6344  max mem: 6531\n",
      "Epoch: [0]  [ 850/5004]  eta: 1:25:10  lr: 0.000001  loss: 6.9248 (6.9324)  time: 1.2203  data: 0.6294  max mem: 6531\n",
      "Epoch: [0]  [ 860/5004]  eta: 1:25:04  lr: 0.000001  loss: 6.9250 (6.9323)  time: 1.2055  data: 0.6234  max mem: 6531\n",
      "Epoch: [0]  [ 870/5004]  eta: 1:24:45  lr: 0.000001  loss: 6.9303 (6.9323)  time: 1.2203  data: 0.6376  max mem: 6531\n",
      "Epoch: [0]  [ 880/5004]  eta: 1:24:36  lr: 0.000001  loss: 6.9215 (6.9321)  time: 1.1976  data: 0.6183  max mem: 6531\n",
      "Epoch: [0]  [ 890/5004]  eta: 1:24:19  lr: 0.000001  loss: 6.9191 (6.9319)  time: 1.2202  data: 0.6411  max mem: 6531\n",
      "Epoch: [0]  [ 900/5004]  eta: 1:24:10  lr: 0.000001  loss: 6.9191 (6.9318)  time: 1.2217  data: 0.6419  max mem: 6531\n",
      "Epoch: [0]  [ 910/5004]  eta: 1:23:53  lr: 0.000001  loss: 6.9200 (6.9318)  time: 1.2116  data: 0.6323  max mem: 6531\n",
      "Epoch: [0]  [ 920/5004]  eta: 1:23:43  lr: 0.000001  loss: 6.9232 (6.9317)  time: 1.1946  data: 0.6128  max mem: 6531\n",
      "Epoch: [0]  [ 930/5004]  eta: 1:23:26  lr: 0.000001  loss: 6.9230 (6.9316)  time: 1.2084  data: 0.6331  max mem: 6531\n",
      "Epoch: [0]  [ 940/5004]  eta: 1:23:21  lr: 0.000001  loss: 6.9210 (6.9315)  time: 1.2711  data: 0.6949  max mem: 6531\n",
      "Epoch: [0]  [ 950/5004]  eta: 1:23:05  lr: 0.000001  loss: 6.9106 (6.9313)  time: 1.2685  data: 0.6835  max mem: 6531\n",
      "Epoch: [0]  [ 960/5004]  eta: 1:22:57  lr: 0.000001  loss: 6.9151 (6.9312)  time: 1.2283  data: 0.6374  max mem: 6531\n",
      "Epoch: [0]  [ 970/5004]  eta: 1:22:37  lr: 0.000001  loss: 6.9245 (6.9311)  time: 1.1823  data: 0.5926  max mem: 6531\n",
      "Epoch: [0]  [ 980/5004]  eta: 1:22:28  lr: 0.000001  loss: 6.9223 (6.9310)  time: 1.1824  data: 0.5974  max mem: 6531\n",
      "Epoch: [0]  [ 990/5004]  eta: 1:22:12  lr: 0.000001  loss: 6.9127 (6.9309)  time: 1.2296  data: 0.6460  max mem: 6531\n",
      "Epoch: [0]  [1000/5004]  eta: 1:22:01  lr: 0.000001  loss: 6.9193 (6.9308)  time: 1.2038  data: 0.6213  max mem: 6531\n",
      "Epoch: [0]  [1010/5004]  eta: 1:21:42  lr: 0.000001  loss: 6.9236 (6.9307)  time: 1.1550  data: 0.5775  max mem: 6531\n",
      "Epoch: [0]  [1020/5004]  eta: 1:21:31  lr: 0.000001  loss: 6.9218 (6.9306)  time: 1.1485  data: 0.5778  max mem: 6531\n",
      "Epoch: [0]  [1030/5004]  eta: 1:21:11  lr: 0.000001  loss: 6.9232 (6.9306)  time: 1.1515  data: 0.5813  max mem: 6531\n",
      "Epoch: [0]  [1040/5004]  eta: 1:21:07  lr: 0.000001  loss: 6.9240 (6.9306)  time: 1.2386  data: 0.6625  max mem: 6531\n",
      "Epoch: [0]  [1050/5004]  eta: 1:20:50  lr: 0.000001  loss: 6.9174 (6.9304)  time: 1.2673  data: 0.6877  max mem: 6531\n",
      "Epoch: [0]  [1060/5004]  eta: 1:20:39  lr: 0.000001  loss: 6.9189 (6.9304)  time: 1.1861  data: 0.6106  max mem: 6531\n",
      "Epoch: [0]  [1070/5004]  eta: 1:20:22  lr: 0.000001  loss: 6.9224 (6.9303)  time: 1.1793  data: 0.6038  max mem: 6531\n",
      "Epoch: [0]  [1080/5004]  eta: 1:20:13  lr: 0.000001  loss: 6.9232 (6.9303)  time: 1.2103  data: 0.6275  max mem: 6531\n",
      "Epoch: [0]  [1090/5004]  eta: 1:19:58  lr: 0.000001  loss: 6.9218 (6.9302)  time: 1.2339  data: 0.6514  max mem: 6531\n",
      "Epoch: [0]  [1100/5004]  eta: 1:19:48  lr: 0.000001  loss: 6.9212 (6.9301)  time: 1.2203  data: 0.6397  max mem: 6531\n",
      "Epoch: [0]  [1110/5004]  eta: 1:19:30  lr: 0.000001  loss: 6.9213 (6.9301)  time: 1.1827  data: 0.6002  max mem: 6531\n",
      "Epoch: [0]  [1120/5004]  eta: 1:19:21  lr: 0.000001  loss: 6.9229 (6.9300)  time: 1.1850  data: 0.5999  max mem: 6531\n",
      "Epoch: [0]  [1130/5004]  eta: 1:19:04  lr: 0.000001  loss: 6.9242 (6.9300)  time: 1.2043  data: 0.6146  max mem: 6531\n",
      "Epoch: [0]  [1140/5004]  eta: 1:18:59  lr: 0.000001  loss: 6.9242 (6.9299)  time: 1.2583  data: 0.6669  max mem: 6531\n",
      "Epoch: [0]  [1150/5004]  eta: 1:18:40  lr: 0.000001  loss: 6.9187 (6.9298)  time: 1.2208  data: 0.6343  max mem: 6531\n",
      "Epoch: [0]  [1160/5004]  eta: 1:18:31  lr: 0.000001  loss: 6.9191 (6.9297)  time: 1.1789  data: 0.5951  max mem: 6531\n",
      "Epoch: [0]  [1170/5004]  eta: 1:18:13  lr: 0.000001  loss: 6.9191 (6.9296)  time: 1.1967  data: 0.6089  max mem: 6531\n",
      "Epoch: [0]  [1180/5004]  eta: 1:18:06  lr: 0.000001  loss: 6.9176 (6.9295)  time: 1.2178  data: 0.6315  max mem: 6531\n",
      "Epoch: [0]  [1190/5004]  eta: 1:17:50  lr: 0.000001  loss: 6.9160 (6.9294)  time: 1.2422  data: 0.6577  max mem: 6531\n",
      "Epoch: [0]  [1200/5004]  eta: 1:17:41  lr: 0.000001  loss: 6.9186 (6.9293)  time: 1.2153  data: 0.6364  max mem: 6531\n",
      "Epoch: [0]  [1210/5004]  eta: 1:17:24  lr: 0.000001  loss: 6.9186 (6.9292)  time: 1.1948  data: 0.6223  max mem: 6531\n",
      "Epoch: [0]  [1220/5004]  eta: 1:17:15  lr: 0.000001  loss: 6.9188 (6.9292)  time: 1.1974  data: 0.6256  max mem: 6531\n",
      "Epoch: [0]  [1230/5004]  eta: 1:16:58  lr: 0.000001  loss: 6.9202 (6.9291)  time: 1.2127  data: 0.6410  max mem: 6531\n",
      "Epoch: [0]  [1240/5004]  eta: 1:16:50  lr: 0.000001  loss: 6.9235 (6.9291)  time: 1.2258  data: 0.6523  max mem: 6531\n",
      "Epoch: [0]  [1250/5004]  eta: 1:16:35  lr: 0.000001  loss: 6.9178 (6.9290)  time: 1.2404  data: 0.6663  max mem: 6531\n",
      "Epoch: [0]  [1260/5004]  eta: 1:16:24  lr: 0.000001  loss: 6.9215 (6.9290)  time: 1.2048  data: 0.6286  max mem: 6531\n",
      "Epoch: [0]  [1270/5004]  eta: 1:16:08  lr: 0.000001  loss: 6.9169 (6.9289)  time: 1.1795  data: 0.5973  max mem: 6531\n",
      "Epoch: [0]  [1280/5004]  eta: 1:15:58  lr: 0.000001  loss: 6.9171 (6.9288)  time: 1.1890  data: 0.6003  max mem: 6531\n",
      "Epoch: [0]  [1290/5004]  eta: 1:15:42  lr: 0.000001  loss: 6.9207 (6.9287)  time: 1.2006  data: 0.6112  max mem: 6531\n",
      "Epoch: [0]  [1300/5004]  eta: 1:15:34  lr: 0.000001  loss: 6.9200 (6.9287)  time: 1.2328  data: 0.6449  max mem: 6531\n",
      "Epoch: [0]  [1310/5004]  eta: 1:15:18  lr: 0.000001  loss: 6.9207 (6.9286)  time: 1.2261  data: 0.6406  max mem: 6531\n",
      "Epoch: [0]  [1320/5004]  eta: 1:15:11  lr: 0.000001  loss: 6.9208 (6.9286)  time: 1.2463  data: 0.6633  max mem: 6531\n",
      "Epoch: [0]  [1330/5004]  eta: 1:14:55  lr: 0.000001  loss: 6.9180 (6.9285)  time: 1.2475  data: 0.6648  max mem: 6531\n",
      "Epoch: [0]  [1340/5004]  eta: 1:14:47  lr: 0.000001  loss: 6.9186 (6.9285)  time: 1.2371  data: 0.6477  max mem: 6531\n",
      "Epoch: [0]  [1350/5004]  eta: 1:14:31  lr: 0.000001  loss: 6.9195 (6.9284)  time: 1.2305  data: 0.6420  max mem: 6531\n",
      "Epoch: [0]  [1360/5004]  eta: 1:14:20  lr: 0.000001  loss: 6.9200 (6.9284)  time: 1.1788  data: 0.5930  max mem: 6531\n",
      "Epoch: [0]  [1370/5004]  eta: 1:14:03  lr: 0.000001  loss: 6.9195 (6.9283)  time: 1.1587  data: 0.5687  max mem: 6531\n",
      "Epoch: [0]  [1380/5004]  eta: 1:13:54  lr: 0.000001  loss: 6.9168 (6.9282)  time: 1.1938  data: 0.6069  max mem: 6531\n",
      "Epoch: [0]  [1390/5004]  eta: 1:13:39  lr: 0.000001  loss: 6.9206 (6.9281)  time: 1.2376  data: 0.6532  max mem: 6531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [1400/5004]  eta: 1:13:29  lr: 0.000001  loss: 6.9210 (6.9281)  time: 1.2137  data: 0.6280  max mem: 6531\n",
      "Epoch: [0]  [1410/5004]  eta: 1:13:13  lr: 0.000001  loss: 6.9215 (6.9280)  time: 1.1844  data: 0.6001  max mem: 6531\n",
      "Epoch: [0]  [1420/5004]  eta: 1:13:02  lr: 0.000001  loss: 6.9163 (6.9279)  time: 1.1819  data: 0.5991  max mem: 6531\n",
      "Epoch: [0]  [1430/5004]  eta: 1:12:47  lr: 0.000001  loss: 6.9103 (6.9278)  time: 1.2057  data: 0.6223  max mem: 6531\n",
      "Epoch: [0]  [1440/5004]  eta: 1:12:39  lr: 0.000001  loss: 6.9186 (6.9278)  time: 1.2519  data: 0.6650  max mem: 6531\n",
      "Epoch: [0]  [1450/5004]  eta: 1:12:24  lr: 0.000001  loss: 6.9197 (6.9277)  time: 1.2360  data: 0.6490  max mem: 6531\n",
      "Epoch: [0]  [1460/5004]  eta: 1:12:14  lr: 0.000001  loss: 6.9191 (6.9276)  time: 1.2171  data: 0.6319  max mem: 6531\n",
      "Epoch: [0]  [1470/5004]  eta: 1:11:58  lr: 0.000001  loss: 6.9205 (6.9276)  time: 1.2093  data: 0.6237  max mem: 6531\n",
      "Epoch: [0]  [1480/5004]  eta: 1:11:50  lr: 0.000001  loss: 6.9226 (6.9275)  time: 1.2203  data: 0.6319  max mem: 6531\n",
      "Epoch: [0]  [1490/5004]  eta: 1:11:37  lr: 0.000001  loss: 6.9155 (6.9275)  time: 1.2768  data: 0.6845  max mem: 6531\n",
      "Epoch: [0]  [1500/5004]  eta: 1:11:27  lr: 0.000001  loss: 6.9181 (6.9275)  time: 1.2504  data: 0.6567  max mem: 6531\n",
      "Epoch: [0]  [1510/5004]  eta: 1:11:11  lr: 0.000001  loss: 6.9185 (6.9274)  time: 1.2071  data: 0.6198  max mem: 6531\n",
      "Epoch: [0]  [1520/5004]  eta: 1:11:03  lr: 0.000001  loss: 6.9159 (6.9273)  time: 1.2525  data: 0.6727  max mem: 6531\n",
      "Epoch: [0]  [1530/5004]  eta: 1:10:48  lr: 0.000001  loss: 6.9177 (6.9273)  time: 1.2360  data: 0.6542  max mem: 6531\n",
      "Epoch: [0]  [1540/5004]  eta: 1:10:39  lr: 0.000001  loss: 6.9220 (6.9272)  time: 1.2311  data: 0.6536  max mem: 6531\n",
      "Epoch: [0]  [1550/5004]  eta: 1:10:25  lr: 0.000001  loss: 6.9241 (6.9272)  time: 1.2617  data: 0.6890  max mem: 6531\n",
      "Epoch: [0]  [1560/5004]  eta: 1:10:15  lr: 0.000001  loss: 6.9173 (6.9271)  time: 1.2162  data: 0.6429  max mem: 6531\n",
      "Epoch: [0]  [1570/5004]  eta: 1:09:59  lr: 0.000001  loss: 6.9191 (6.9271)  time: 1.2018  data: 0.6225  max mem: 6531\n",
      "Epoch: [0]  [1580/5004]  eta: 1:09:51  lr: 0.000001  loss: 6.9174 (6.9270)  time: 1.2566  data: 0.6695  max mem: 6531\n",
      "Epoch: [0]  [1590/5004]  eta: 1:09:36  lr: 0.000001  loss: 6.9150 (6.9269)  time: 1.2504  data: 0.6641  max mem: 6531\n",
      "Epoch: [0]  [1600/5004]  eta: 1:09:26  lr: 0.000001  loss: 6.9111 (6.9268)  time: 1.2045  data: 0.6185  max mem: 6531\n",
      "Epoch: [0]  [1610/5004]  eta: 1:09:09  lr: 0.000001  loss: 6.9189 (6.9268)  time: 1.1675  data: 0.5834  max mem: 6531\n",
      "Epoch: [0]  [1620/5004]  eta: 1:08:59  lr: 0.000001  loss: 6.9223 (6.9268)  time: 1.1612  data: 0.5759  max mem: 6531\n",
      "Epoch: [0]  [1630/5004]  eta: 1:08:43  lr: 0.000001  loss: 6.9181 (6.9267)  time: 1.1869  data: 0.5953  max mem: 6531\n",
      "Epoch: [0]  [1640/5004]  eta: 1:08:34  lr: 0.000001  loss: 6.9120 (6.9266)  time: 1.2151  data: 0.6276  max mem: 6531\n",
      "Epoch: [0]  [1650/5004]  eta: 1:08:19  lr: 0.000001  loss: 6.9120 (6.9265)  time: 1.2282  data: 0.6467  max mem: 6531\n",
      "Epoch: [0]  [1660/5004]  eta: 1:08:08  lr: 0.000001  loss: 6.9155 (6.9265)  time: 1.1895  data: 0.6078  max mem: 6531\n",
      "Epoch: [0]  [1670/5004]  eta: 1:07:53  lr: 0.000001  loss: 6.9155 (6.9264)  time: 1.1775  data: 0.5948  max mem: 6531\n",
      "Epoch: [0]  [1680/5004]  eta: 1:07:45  lr: 0.000001  loss: 6.9216 (6.9264)  time: 1.2387  data: 0.6555  max mem: 6531\n",
      "Epoch: [0]  [1690/5004]  eta: 1:07:29  lr: 0.000001  loss: 6.9216 (6.9263)  time: 1.2354  data: 0.6535  max mem: 6531\n",
      "Epoch: [0]  [1700/5004]  eta: 1:07:18  lr: 0.000001  loss: 6.9181 (6.9263)  time: 1.1636  data: 0.5807  max mem: 6531\n",
      "Epoch: [0]  [1710/5004]  eta: 1:07:03  lr: 0.000001  loss: 6.9193 (6.9263)  time: 1.1667  data: 0.5824  max mem: 6531\n",
      "Epoch: [0]  [1720/5004]  eta: 1:06:53  lr: 0.000001  loss: 6.9193 (6.9262)  time: 1.2148  data: 0.6300  max mem: 6531\n",
      "Epoch: [0]  [1730/5004]  eta: 1:06:38  lr: 0.000001  loss: 6.9186 (6.9262)  time: 1.2321  data: 0.6445  max mem: 6531\n",
      "Epoch: [0]  [1740/5004]  eta: 1:06:28  lr: 0.000001  loss: 6.9150 (6.9261)  time: 1.2101  data: 0.6230  max mem: 6531\n",
      "Epoch: [0]  [1750/5004]  eta: 1:06:13  lr: 0.000001  loss: 6.9079 (6.9260)  time: 1.2023  data: 0.6203  max mem: 6531\n",
      "Epoch: [0]  [1760/5004]  eta: 1:06:02  lr: 0.000001  loss: 6.9137 (6.9260)  time: 1.1847  data: 0.6020  max mem: 6531\n",
      "Epoch: [0]  [1770/5004]  eta: 1:05:48  lr: 0.000001  loss: 6.9190 (6.9259)  time: 1.1870  data: 0.6032  max mem: 6531\n",
      "Epoch: [0]  [1780/5004]  eta: 1:05:39  lr: 0.000001  loss: 6.9215 (6.9259)  time: 1.2401  data: 0.6574  max mem: 6531\n",
      "Epoch: [0]  [1790/5004]  eta: 1:05:24  lr: 0.000001  loss: 6.9127 (6.9258)  time: 1.2304  data: 0.6480  max mem: 6531\n",
      "Epoch: [0]  [1800/5004]  eta: 1:05:13  lr: 0.000001  loss: 6.9087 (6.9257)  time: 1.1782  data: 0.5929  max mem: 6531\n",
      "Epoch: [0]  [1810/5004]  eta: 1:04:58  lr: 0.000001  loss: 6.9147 (6.9257)  time: 1.1750  data: 0.5886  max mem: 6531\n",
      "Epoch: [0]  [1820/5004]  eta: 1:04:47  lr: 0.000001  loss: 6.9170 (6.9257)  time: 1.1842  data: 0.5988  max mem: 6531\n",
      "Epoch: [0]  [1830/5004]  eta: 1:04:33  lr: 0.000001  loss: 6.9124 (6.9256)  time: 1.2258  data: 0.6059  max mem: 6531\n",
      "Epoch: [0]  [1840/5004]  eta: 1:04:23  lr: 0.000001  loss: 6.9152 (6.9255)  time: 1.2317  data: 0.6110  max mem: 6531\n",
      "Epoch: [0]  [1850/5004]  eta: 1:04:08  lr: 0.000001  loss: 6.9119 (6.9254)  time: 1.1977  data: 0.6104  max mem: 6531\n",
      "Epoch: [0]  [1860/5004]  eta: 1:03:57  lr: 0.000001  loss: 6.9103 (6.9254)  time: 1.1876  data: 0.6002  max mem: 6531\n",
      "Epoch: [0]  [1870/5004]  eta: 1:03:42  lr: 0.000001  loss: 6.9143 (6.9253)  time: 1.1721  data: 0.5859  max mem: 6531\n",
      "Epoch: [0]  [1880/5004]  eta: 1:03:32  lr: 0.000001  loss: 6.9175 (6.9253)  time: 1.1835  data: 0.5942  max mem: 6531\n",
      "Epoch: [0]  [1890/5004]  eta: 1:03:17  lr: 0.000001  loss: 6.9121 (6.9252)  time: 1.1897  data: 0.5977  max mem: 6531\n",
      "Epoch: [0]  [1900/5004]  eta: 1:03:05  lr: 0.000001  loss: 6.9084 (6.9251)  time: 1.1558  data: 0.5682  max mem: 6531\n",
      "Epoch: [0]  [1910/5004]  eta: 1:02:50  lr: 0.000001  loss: 6.9099 (6.9251)  time: 1.1505  data: 0.5665  max mem: 6531\n",
      "Epoch: [0]  [1920/5004]  eta: 1:02:39  lr: 0.000001  loss: 6.9109 (6.9250)  time: 1.1791  data: 0.5920  max mem: 6531\n",
      "Epoch: [0]  [1930/5004]  eta: 1:02:25  lr: 0.000001  loss: 6.9158 (6.9250)  time: 1.1908  data: 0.5999  max mem: 6531\n",
      "Epoch: [0]  [1940/5004]  eta: 1:02:15  lr: 0.000001  loss: 6.9149 (6.9249)  time: 1.2149  data: 0.6274  max mem: 6531\n",
      "Epoch: [0]  [1950/5004]  eta: 1:02:01  lr: 0.000001  loss: 6.9112 (6.9248)  time: 1.2224  data: 0.6391  max mem: 6531\n",
      "Epoch: [0]  [1960/5004]  eta: 1:01:50  lr: 0.000001  loss: 6.9112 (6.9247)  time: 1.1859  data: 0.6080  max mem: 6531\n",
      "Epoch: [0]  [1970/5004]  eta: 1:01:35  lr: 0.000001  loss: 6.9092 (6.9247)  time: 1.1815  data: 0.6066  max mem: 6531\n",
      "Epoch: [0]  [1980/5004]  eta: 1:01:25  lr: 0.000001  loss: 6.9103 (6.9246)  time: 1.2169  data: 0.6409  max mem: 6531\n",
      "Epoch: [0]  [1990/5004]  eta: 1:01:11  lr: 0.000001  loss: 6.9137 (6.9246)  time: 1.2204  data: 0.6498  max mem: 6531\n",
      "Epoch: [0]  [2000/5004]  eta: 1:01:00  lr: 0.000001  loss: 6.9132 (6.9245)  time: 1.2098  data: 0.6455  max mem: 6531\n",
      "Epoch: [0]  [2010/5004]  eta: 1:00:46  lr: 0.000001  loss: 6.9156 (6.9245)  time: 1.1955  data: 0.6289  max mem: 6531\n",
      "Epoch: [0]  [2020/5004]  eta: 1:00:35  lr: 0.000001  loss: 6.9120 (6.9244)  time: 1.1712  data: 0.6052  max mem: 6531\n",
      "Epoch: [0]  [2030/5004]  eta: 1:00:20  lr: 0.000001  loss: 6.9065 (6.9243)  time: 1.1556  data: 0.5913  max mem: 6531\n",
      "Epoch: [0]  [2040/5004]  eta: 1:00:10  lr: 0.000001  loss: 6.9104 (6.9242)  time: 1.1992  data: 0.6325  max mem: 6531\n",
      "Epoch: [0]  [2050/5004]  eta: 0:59:55  lr: 0.000001  loss: 6.9138 (6.9242)  time: 1.2081  data: 0.6414  max mem: 6531\n",
      "Epoch: [0]  [2060/5004]  eta: 0:59:44  lr: 0.000001  loss: 6.9087 (6.9241)  time: 1.1740  data: 0.6100  max mem: 6531\n",
      "Epoch: [0]  [2070/5004]  eta: 0:59:30  lr: 0.000001  loss: 6.9097 (6.9240)  time: 1.1768  data: 0.6125  max mem: 6531\n",
      "Epoch: [0]  [2080/5004]  eta: 0:59:19  lr: 0.000001  loss: 6.9121 (6.9240)  time: 1.2048  data: 0.6422  max mem: 6531\n",
      "Epoch: [0]  [2090/5004]  eta: 0:59:05  lr: 0.000001  loss: 6.9142 (6.9240)  time: 1.2146  data: 0.6565  max mem: 6531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [2100/5004]  eta: 0:58:55  lr: 0.000001  loss: 6.9200 (6.9240)  time: 1.2154  data: 0.6581  max mem: 6531\n",
      "Epoch: [0]  [2110/5004]  eta: 0:58:40  lr: 0.000001  loss: 6.9210 (6.9240)  time: 1.2059  data: 0.6496  max mem: 6531\n",
      "Epoch: [0]  [2120/5004]  eta: 0:58:29  lr: 0.000001  loss: 6.9112 (6.9239)  time: 1.1641  data: 0.6056  max mem: 6531\n",
      "Epoch: [0]  [2130/5004]  eta: 0:58:15  lr: 0.000001  loss: 6.9110 (6.9239)  time: 1.1823  data: 0.6206  max mem: 6531\n",
      "Epoch: [0]  [2140/5004]  eta: 0:58:05  lr: 0.000001  loss: 6.9138 (6.9238)  time: 1.2146  data: 0.6518  max mem: 6531\n",
      "Epoch: [0]  [2150/5004]  eta: 0:57:50  lr: 0.000001  loss: 6.9079 (6.9237)  time: 1.1991  data: 0.6376  max mem: 6531\n",
      "Epoch: [0]  [2160/5004]  eta: 0:57:39  lr: 0.000001  loss: 6.9120 (6.9237)  time: 1.1717  data: 0.6092  max mem: 6531\n",
      "Epoch: [0]  [2170/5004]  eta: 0:57:25  lr: 0.000001  loss: 6.9136 (6.9236)  time: 1.1578  data: 0.5944  max mem: 6531\n",
      "Epoch: [0]  [2180/5004]  eta: 0:57:14  lr: 0.000001  loss: 6.9114 (6.9236)  time: 1.1870  data: 0.6215  max mem: 6531\n",
      "Epoch: [0]  [2190/5004]  eta: 0:57:00  lr: 0.000001  loss: 6.9130 (6.9235)  time: 1.2119  data: 0.6444  max mem: 6531\n",
      "Epoch: [0]  [2200/5004]  eta: 0:56:49  lr: 0.000001  loss: 6.9098 (6.9234)  time: 1.1673  data: 0.6034  max mem: 6531\n",
      "Epoch: [0]  [2210/5004]  eta: 0:56:34  lr: 0.000001  loss: 6.9064 (6.9234)  time: 1.1582  data: 0.6001  max mem: 6531\n",
      "Epoch: [0]  [2220/5004]  eta: 0:56:23  lr: 0.000001  loss: 6.9109 (6.9233)  time: 1.1690  data: 0.6146  max mem: 6531\n",
      "Epoch: [0]  [2230/5004]  eta: 0:56:09  lr: 0.000001  loss: 6.9155 (6.9233)  time: 1.1707  data: 0.6161  max mem: 6531\n",
      "Epoch: [0]  [2240/5004]  eta: 0:55:59  lr: 0.000001  loss: 6.9145 (6.9233)  time: 1.2254  data: 0.6708  max mem: 6531\n",
      "Epoch: [0]  [2250/5004]  eta: 0:55:44  lr: 0.000001  loss: 6.9111 (6.9232)  time: 1.1986  data: 0.6418  max mem: 6531\n",
      "Epoch: [0]  [2260/5004]  eta: 0:55:33  lr: 0.000001  loss: 6.9109 (6.9232)  time: 1.1454  data: 0.5878  max mem: 6531\n",
      "Epoch: [0]  [2270/5004]  eta: 0:55:19  lr: 0.000001  loss: 6.9090 (6.9231)  time: 1.1705  data: 0.6139  max mem: 6531\n",
      "Epoch: [0]  [2280/5004]  eta: 0:55:08  lr: 0.000001  loss: 6.9090 (6.9230)  time: 1.1897  data: 0.6362  max mem: 6531\n",
      "Epoch: [0]  [2290/5004]  eta: 0:54:55  lr: 0.000001  loss: 6.9122 (6.9230)  time: 1.2101  data: 0.6510  max mem: 6531\n",
      "Epoch: [0]  [2300/5004]  eta: 0:54:43  lr: 0.000001  loss: 6.9111 (6.9229)  time: 1.1945  data: 0.6335  max mem: 6531\n",
      "Epoch: [0]  [2310/5004]  eta: 0:54:30  lr: 0.000001  loss: 6.9074 (6.9228)  time: 1.1792  data: 0.6276  max mem: 6531\n",
      "Epoch: [0]  [2320/5004]  eta: 0:54:18  lr: 0.000001  loss: 6.9124 (6.9228)  time: 1.1725  data: 0.6191  max mem: 6531\n",
      "Epoch: [0]  [2330/5004]  eta: 0:54:04  lr: 0.000001  loss: 6.9142 (6.9228)  time: 1.1686  data: 0.6122  max mem: 6531\n",
      "Epoch: [0]  [2340/5004]  eta: 0:53:53  lr: 0.000001  loss: 6.9142 (6.9227)  time: 1.1884  data: 0.6274  max mem: 6531\n",
      "Epoch: [0]  [2350/5004]  eta: 0:53:39  lr: 0.000001  loss: 6.9079 (6.9227)  time: 1.1795  data: 0.6217  max mem: 6531\n",
      "Epoch: [0]  [2360/5004]  eta: 0:53:28  lr: 0.000001  loss: 6.9079 (6.9226)  time: 1.1655  data: 0.6148  max mem: 6531\n",
      "Epoch: [0]  [2370/5004]  eta: 0:53:14  lr: 0.000001  loss: 6.9151 (6.9226)  time: 1.1756  data: 0.6168  max mem: 6531\n",
      "Epoch: [0]  [2380/5004]  eta: 0:53:03  lr: 0.000001  loss: 6.9154 (6.9226)  time: 1.1757  data: 0.6184  max mem: 6531\n",
      "Epoch: [0]  [2390/5004]  eta: 0:52:49  lr: 0.000001  loss: 6.9120 (6.9225)  time: 1.1900  data: 0.6362  max mem: 6531\n",
      "Epoch: [0]  [2400/5004]  eta: 0:52:38  lr: 0.000001  loss: 6.9077 (6.9225)  time: 1.2054  data: 0.6459  max mem: 6531\n",
      "Epoch: [0]  [2410/5004]  eta: 0:52:25  lr: 0.000001  loss: 6.9090 (6.9224)  time: 1.1959  data: 0.6369  max mem: 6531\n",
      "Epoch: [0]  [2420/5004]  eta: 0:52:14  lr: 0.000001  loss: 6.9093 (6.9224)  time: 1.1937  data: 0.6367  max mem: 6531\n",
      "Epoch: [0]  [2430/5004]  eta: 0:51:59  lr: 0.000001  loss: 6.9093 (6.9223)  time: 1.1675  data: 0.6092  max mem: 6531\n",
      "Epoch: [0]  [2440/5004]  eta: 0:51:49  lr: 0.000001  loss: 6.9100 (6.9223)  time: 1.1802  data: 0.6193  max mem: 6531\n",
      "Epoch: [0]  [2450/5004]  eta: 0:51:35  lr: 0.000001  loss: 6.9124 (6.9223)  time: 1.1950  data: 0.6355  max mem: 6531\n",
      "Epoch: [0]  [2460/5004]  eta: 0:51:24  lr: 0.000001  loss: 6.9105 (6.9222)  time: 1.1730  data: 0.6187  max mem: 6531\n",
      "Epoch: [0]  [2470/5004]  eta: 0:51:10  lr: 0.000001  loss: 6.9159 (6.9222)  time: 1.1718  data: 0.6141  max mem: 6531\n",
      "Epoch: [0]  [2480/5004]  eta: 0:50:59  lr: 0.000001  loss: 6.9159 (6.9222)  time: 1.2069  data: 0.6482  max mem: 6531\n",
      "Epoch: [0]  [2490/5004]  eta: 0:50:46  lr: 0.000001  loss: 6.9133 (6.9221)  time: 1.2091  data: 0.6497  max mem: 6531\n",
      "Epoch: [0]  [2500/5004]  eta: 0:50:34  lr: 0.000001  loss: 6.9081 (6.9221)  time: 1.1688  data: 0.6107  max mem: 6531\n",
      "Epoch: [0]  [2510/5004]  eta: 0:50:21  lr: 0.000001  loss: 6.9048 (6.9220)  time: 1.1970  data: 0.6449  max mem: 6531\n",
      "Epoch: [0]  [2520/5004]  eta: 0:50:09  lr: 0.000001  loss: 6.9049 (6.9220)  time: 1.1820  data: 0.6300  max mem: 6531\n",
      "Epoch: [0]  [2530/5004]  eta: 0:49:56  lr: 0.000001  loss: 6.9135 (6.9219)  time: 1.1491  data: 0.5967  max mem: 6531\n",
      "Epoch: [0]  [2540/5004]  eta: 0:49:44  lr: 0.000001  loss: 6.9118 (6.9219)  time: 1.1612  data: 0.6054  max mem: 6531\n",
      "Epoch: [0]  [2550/5004]  eta: 0:49:31  lr: 0.000001  loss: 6.9094 (6.9218)  time: 1.1674  data: 0.6122  max mem: 6531\n",
      "Epoch: [0]  [2560/5004]  eta: 0:49:20  lr: 0.000001  loss: 6.9137 (6.9218)  time: 1.1954  data: 0.6415  max mem: 6531\n",
      "Epoch: [0]  [2570/5004]  eta: 0:49:06  lr: 0.000001  loss: 6.9077 (6.9217)  time: 1.1797  data: 0.6244  max mem: 6531\n",
      "Epoch: [0]  [2580/5004]  eta: 0:48:55  lr: 0.000001  loss: 6.9175 (6.9217)  time: 1.1731  data: 0.6185  max mem: 6531\n",
      "Epoch: [0]  [2590/5004]  eta: 0:48:42  lr: 0.000001  loss: 6.9127 (6.9217)  time: 1.2294  data: 0.6749  max mem: 6531\n",
      "Epoch: [0]  [2600/5004]  eta: 0:48:31  lr: 0.000001  loss: 6.9120 (6.9216)  time: 1.2197  data: 0.6669  max mem: 6531\n",
      "Epoch: [0]  [2610/5004]  eta: 0:48:17  lr: 0.000001  loss: 6.9074 (6.9216)  time: 1.1564  data: 0.6007  max mem: 6531\n",
      "Epoch: [0]  [2620/5004]  eta: 0:48:05  lr: 0.000001  loss: 6.9060 (6.9216)  time: 1.1413  data: 0.5829  max mem: 6531\n",
      "Epoch: [0]  [2630/5004]  eta: 0:47:52  lr: 0.000001  loss: 6.9079 (6.9215)  time: 1.1592  data: 0.6033  max mem: 6531\n",
      "Epoch: [0]  [2640/5004]  eta: 0:47:41  lr: 0.000001  loss: 6.9153 (6.9215)  time: 1.1894  data: 0.6338  max mem: 6531\n",
      "Epoch: [0]  [2650/5004]  eta: 0:47:27  lr: 0.000001  loss: 6.9135 (6.9215)  time: 1.2105  data: 0.6548  max mem: 6531\n",
      "Epoch: [0]  [2660/5004]  eta: 0:47:16  lr: 0.000001  loss: 6.9070 (6.9214)  time: 1.1996  data: 0.6443  max mem: 6531\n",
      "Epoch: [0]  [2670/5004]  eta: 0:47:03  lr: 0.000001  loss: 6.9077 (6.9214)  time: 1.1741  data: 0.6218  max mem: 6531\n",
      "Epoch: [0]  [2680/5004]  eta: 0:46:51  lr: 0.000001  loss: 6.9077 (6.9213)  time: 1.1626  data: 0.6071  max mem: 6531\n",
      "Epoch: [0]  [2690/5004]  eta: 0:46:38  lr: 0.000001  loss: 6.9093 (6.9213)  time: 1.1710  data: 0.6029  max mem: 6531\n",
      "Epoch: [0]  [2700/5004]  eta: 0:46:26  lr: 0.000001  loss: 6.9100 (6.9212)  time: 1.1636  data: 0.6007  max mem: 6531\n",
      "Epoch: [0]  [2710/5004]  eta: 0:46:13  lr: 0.000001  loss: 6.9100 (6.9212)  time: 1.1835  data: 0.6334  max mem: 6531\n",
      "Epoch: [0]  [2720/5004]  eta: 0:46:02  lr: 0.000001  loss: 6.9061 (6.9212)  time: 1.2167  data: 0.6631  max mem: 6531\n",
      "Epoch: [0]  [2730/5004]  eta: 0:45:49  lr: 0.000001  loss: 6.9083 (6.9211)  time: 1.2147  data: 0.6589  max mem: 6531\n",
      "Epoch: [0]  [2740/5004]  eta: 0:45:38  lr: 0.000001  loss: 6.9097 (6.9211)  time: 1.2397  data: 0.6846  max mem: 6531\n",
      "Epoch: [0]  [2750/5004]  eta: 0:45:25  lr: 0.000001  loss: 6.9092 (6.9210)  time: 1.2276  data: 0.6719  max mem: 6531\n",
      "Epoch: [0]  [2760/5004]  eta: 0:45:14  lr: 0.000001  loss: 6.9092 (6.9210)  time: 1.1816  data: 0.6249  max mem: 6531\n",
      "Epoch: [0]  [2770/5004]  eta: 0:45:00  lr: 0.000001  loss: 6.9096 (6.9209)  time: 1.1756  data: 0.6159  max mem: 6531\n",
      "Epoch: [0]  [2780/5004]  eta: 0:44:49  lr: 0.000001  loss: 6.9056 (6.9209)  time: 1.1610  data: 0.6015  max mem: 6531\n",
      "Epoch: [0]  [2790/5004]  eta: 0:44:36  lr: 0.000001  loss: 6.9056 (6.9208)  time: 1.1688  data: 0.6063  max mem: 6531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [2800/5004]  eta: 0:44:24  lr: 0.000001  loss: 6.9104 (6.9208)  time: 1.1997  data: 0.6372  max mem: 6531\n",
      "Epoch: [0]  [2810/5004]  eta: 0:44:11  lr: 0.000001  loss: 6.9104 (6.9208)  time: 1.1854  data: 0.6266  max mem: 6531\n",
      "Epoch: [0]  [2820/5004]  eta: 0:44:00  lr: 0.000001  loss: 6.9095 (6.9207)  time: 1.1631  data: 0.6036  max mem: 6531\n",
      "Epoch: [0]  [2830/5004]  eta: 0:43:47  lr: 0.000001  loss: 6.9095 (6.9207)  time: 1.1883  data: 0.6339  max mem: 6531\n",
      "Epoch: [0]  [2840/5004]  eta: 0:43:35  lr: 0.000001  loss: 6.9104 (6.9207)  time: 1.2137  data: 0.6601  max mem: 6531\n",
      "Epoch: [0]  [2850/5004]  eta: 0:43:22  lr: 0.000001  loss: 6.9022 (6.9206)  time: 1.1904  data: 0.6338  max mem: 6531\n",
      "Epoch: [0]  [2860/5004]  eta: 0:43:11  lr: 0.000001  loss: 6.9022 (6.9205)  time: 1.1608  data: 0.6083  max mem: 6531\n",
      "Epoch: [0]  [2870/5004]  eta: 0:42:58  lr: 0.000001  loss: 6.9059 (6.9205)  time: 1.1838  data: 0.6304  max mem: 6531\n",
      "Epoch: [0]  [2880/5004]  eta: 0:42:46  lr: 0.000001  loss: 6.9060 (6.9204)  time: 1.1957  data: 0.6422  max mem: 6531\n",
      "Epoch: [0]  [2890/5004]  eta: 0:42:33  lr: 0.000001  loss: 6.9060 (6.9204)  time: 1.1939  data: 0.6353  max mem: 6531\n",
      "Epoch: [0]  [2900/5004]  eta: 0:42:22  lr: 0.000001  loss: 6.9064 (6.9204)  time: 1.2097  data: 0.6504  max mem: 6531\n",
      "Epoch: [0]  [2910/5004]  eta: 0:42:09  lr: 0.000001  loss: 6.9107 (6.9203)  time: 1.2051  data: 0.6508  max mem: 6531\n",
      "Epoch: [0]  [2920/5004]  eta: 0:41:57  lr: 0.000001  loss: 6.9107 (6.9203)  time: 1.1736  data: 0.6176  max mem: 6531\n",
      "Epoch: [0]  [2930/5004]  eta: 0:41:44  lr: 0.000001  loss: 6.9057 (6.9203)  time: 1.1513  data: 0.5980  max mem: 6531\n",
      "Epoch: [0]  [2940/5004]  eta: 0:41:33  lr: 0.000001  loss: 6.9142 (6.9202)  time: 1.1976  data: 0.6457  max mem: 6531\n",
      "Epoch: [0]  [2950/5004]  eta: 0:41:20  lr: 0.000001  loss: 6.9132 (6.9202)  time: 1.2138  data: 0.6605  max mem: 6531\n",
      "Epoch: [0]  [2960/5004]  eta: 0:41:09  lr: 0.000001  loss: 6.9132 (6.9202)  time: 1.1911  data: 0.6383  max mem: 6531\n",
      "Epoch: [0]  [2970/5004]  eta: 0:40:55  lr: 0.000001  loss: 6.9136 (6.9201)  time: 1.1705  data: 0.6168  max mem: 6531\n",
      "Epoch: [0]  [2980/5004]  eta: 0:40:44  lr: 0.000001  loss: 6.9124 (6.9201)  time: 1.1653  data: 0.6104  max mem: 6531\n",
      "Epoch: [0]  [2990/5004]  eta: 0:40:31  lr: 0.000001  loss: 6.9124 (6.9201)  time: 1.1924  data: 0.6348  max mem: 6531\n",
      "Epoch: [0]  [3000/5004]  eta: 0:40:20  lr: 0.000001  loss: 6.9093 (6.9200)  time: 1.2163  data: 0.6554  max mem: 6531\n",
      "Epoch: [0]  [3010/5004]  eta: 0:40:07  lr: 0.000001  loss: 6.9069 (6.9200)  time: 1.1899  data: 0.6353  max mem: 6531\n",
      "Epoch: [0]  [3020/5004]  eta: 0:39:55  lr: 0.000001  loss: 6.9060 (6.9199)  time: 1.1589  data: 0.6045  max mem: 6531\n",
      "Epoch: [0]  [3030/5004]  eta: 0:39:42  lr: 0.000001  loss: 6.9019 (6.9199)  time: 1.1851  data: 0.6278  max mem: 6531\n",
      "Epoch: [0]  [3040/5004]  eta: 0:39:31  lr: 0.000001  loss: 6.9065 (6.9199)  time: 1.2024  data: 0.6445  max mem: 6531\n",
      "Epoch: [0]  [3050/5004]  eta: 0:39:18  lr: 0.000001  loss: 6.9066 (6.9198)  time: 1.2329  data: 0.6764  max mem: 6531\n",
      "Epoch: [0]  [3060/5004]  eta: 0:39:07  lr: 0.000001  loss: 6.9068 (6.9198)  time: 1.2147  data: 0.6617  max mem: 6531\n",
      "Epoch: [0]  [3070/5004]  eta: 0:38:54  lr: 0.000001  loss: 6.9051 (6.9197)  time: 1.1578  data: 0.6031  max mem: 6531\n",
      "Epoch: [0]  [3080/5004]  eta: 0:38:42  lr: 0.000001  loss: 6.9051 (6.9197)  time: 1.1668  data: 0.6105  max mem: 6531\n",
      "Epoch: [0]  [3090/5004]  eta: 0:38:29  lr: 0.000001  loss: 6.9050 (6.9197)  time: 1.1945  data: 0.6382  max mem: 6531\n",
      "Epoch: [0]  [3100/5004]  eta: 0:38:18  lr: 0.000001  loss: 6.9023 (6.9196)  time: 1.2235  data: 0.6680  max mem: 6531\n",
      "Epoch: [0]  [3110/5004]  eta: 0:38:05  lr: 0.000001  loss: 6.9023 (6.9196)  time: 1.2119  data: 0.6576  max mem: 6531\n",
      "Epoch: [0]  [3120/5004]  eta: 0:37:54  lr: 0.000001  loss: 6.9128 (6.9195)  time: 1.1715  data: 0.6154  max mem: 6531\n",
      "Epoch: [0]  [3130/5004]  eta: 0:37:41  lr: 0.000001  loss: 6.9061 (6.9195)  time: 1.1655  data: 0.6081  max mem: 6531\n",
      "Epoch: [0]  [3140/5004]  eta: 0:37:29  lr: 0.000001  loss: 6.9026 (6.9194)  time: 1.1655  data: 0.6082  max mem: 6531\n",
      "Epoch: [0]  [3150/5004]  eta: 0:37:16  lr: 0.000001  loss: 6.9026 (6.9194)  time: 1.1576  data: 0.6012  max mem: 6531\n",
      "Epoch: [0]  [3160/5004]  eta: 0:37:04  lr: 0.000001  loss: 6.9036 (6.9193)  time: 1.1707  data: 0.6163  max mem: 6531\n",
      "Epoch: [0]  [3170/5004]  eta: 0:36:51  lr: 0.000001  loss: 6.9062 (6.9193)  time: 1.1607  data: 0.6078  max mem: 6531\n",
      "Epoch: [0]  [3180/5004]  eta: 0:36:40  lr: 0.000001  loss: 6.9062 (6.9193)  time: 1.1451  data: 0.5917  max mem: 6531\n",
      "Epoch: [0]  [3190/5004]  eta: 0:36:27  lr: 0.000001  loss: 6.9017 (6.9192)  time: 1.1691  data: 0.6158  max mem: 6531\n",
      "Epoch: [0]  [3200/5004]  eta: 0:36:16  lr: 0.000001  loss: 6.9034 (6.9192)  time: 1.2221  data: 0.6660  max mem: 6531\n",
      "Epoch: [0]  [3210/5004]  eta: 0:36:03  lr: 0.000001  loss: 6.9084 (6.9192)  time: 1.2027  data: 0.6442  max mem: 6531\n",
      "Epoch: [0]  [3220/5004]  eta: 0:35:51  lr: 0.000001  loss: 6.9110 (6.9191)  time: 1.1531  data: 0.5983  max mem: 6531\n",
      "Epoch: [0]  [3230/5004]  eta: 0:35:38  lr: 0.000001  loss: 6.9080 (6.9191)  time: 1.1650  data: 0.6106  max mem: 6531\n",
      "Epoch: [0]  [3240/5004]  eta: 0:35:27  lr: 0.000001  loss: 6.9074 (6.9191)  time: 1.1869  data: 0.6304  max mem: 6531\n",
      "Epoch: [0]  [3250/5004]  eta: 0:35:14  lr: 0.000001  loss: 6.9087 (6.9190)  time: 1.2207  data: 0.6619  max mem: 6531\n",
      "Epoch: [0]  [3260/5004]  eta: 0:35:03  lr: 0.000001  loss: 6.9023 (6.9190)  time: 1.2134  data: 0.6545  max mem: 6531\n",
      "Epoch: [0]  [3270/5004]  eta: 0:34:50  lr: 0.000001  loss: 6.9018 (6.9189)  time: 1.2155  data: 0.6564  max mem: 6531\n",
      "Epoch: [0]  [3280/5004]  eta: 0:34:38  lr: 0.000001  loss: 6.9069 (6.9189)  time: 1.2015  data: 0.6444  max mem: 6531\n",
      "Epoch: [0]  [3290/5004]  eta: 0:34:26  lr: 0.000001  loss: 6.9074 (6.9189)  time: 1.1713  data: 0.6150  max mem: 6531\n",
      "Epoch: [0]  [3300/5004]  eta: 0:34:14  lr: 0.000001  loss: 6.9084 (6.9188)  time: 1.2028  data: 0.6451  max mem: 6531\n",
      "Epoch: [0]  [3310/5004]  eta: 0:34:01  lr: 0.000001  loss: 6.9038 (6.9188)  time: 1.1817  data: 0.6262  max mem: 6531\n",
      "Epoch: [0]  [3320/5004]  eta: 0:33:50  lr: 0.000001  loss: 6.9044 (6.9188)  time: 1.1594  data: 0.6021  max mem: 6531\n",
      "Epoch: [0]  [3330/5004]  eta: 0:33:37  lr: 0.000001  loss: 6.9098 (6.9187)  time: 1.1864  data: 0.6303  max mem: 6531\n",
      "Epoch: [0]  [3340/5004]  eta: 0:33:25  lr: 0.000001  loss: 6.9071 (6.9187)  time: 1.1688  data: 0.6106  max mem: 6531\n",
      "Epoch: [0]  [3350/5004]  eta: 0:33:13  lr: 0.000001  loss: 6.9063 (6.9187)  time: 1.1761  data: 0.6137  max mem: 6531\n",
      "Epoch: [0]  [3360/5004]  eta: 0:33:01  lr: 0.000001  loss: 6.9104 (6.9186)  time: 1.1909  data: 0.6313  max mem: 6531\n",
      "Epoch: [0]  [3370/5004]  eta: 0:32:48  lr: 0.000001  loss: 6.9104 (6.9186)  time: 1.1693  data: 0.6142  max mem: 6531\n",
      "Epoch: [0]  [3380/5004]  eta: 0:32:37  lr: 0.000001  loss: 6.9043 (6.9186)  time: 1.1914  data: 0.6336  max mem: 6531\n",
      "Epoch: [0]  [3390/5004]  eta: 0:32:24  lr: 0.000001  loss: 6.9087 (6.9185)  time: 1.1933  data: 0.6369  max mem: 6531\n",
      "Epoch: [0]  [3400/5004]  eta: 0:32:12  lr: 0.000001  loss: 6.9048 (6.9185)  time: 1.1924  data: 0.6394  max mem: 6531\n",
      "Epoch: [0]  [3410/5004]  eta: 0:32:00  lr: 0.000001  loss: 6.9058 (6.9184)  time: 1.2150  data: 0.6571  max mem: 6531\n",
      "Epoch: [0]  [3420/5004]  eta: 0:31:48  lr: 0.000001  loss: 6.9046 (6.9184)  time: 1.1822  data: 0.6247  max mem: 6531\n",
      "Epoch: [0]  [3430/5004]  eta: 0:31:35  lr: 0.000001  loss: 6.9027 (6.9184)  time: 1.1545  data: 0.5993  max mem: 6531\n",
      "Epoch: [0]  [3440/5004]  eta: 0:31:24  lr: 0.000001  loss: 6.9043 (6.9183)  time: 1.1867  data: 0.6310  max mem: 6531\n",
      "Epoch: [0]  [3450/5004]  eta: 0:31:11  lr: 0.000001  loss: 6.9055 (6.9183)  time: 1.1872  data: 0.6290  max mem: 6531\n",
      "Epoch: [0]  [3460/5004]  eta: 0:31:00  lr: 0.000001  loss: 6.9055 (6.9182)  time: 1.1850  data: 0.6255  max mem: 6531\n",
      "Epoch: [0]  [3470/5004]  eta: 0:30:47  lr: 0.000001  loss: 6.9065 (6.9182)  time: 1.1773  data: 0.6163  max mem: 6531\n",
      "Epoch: [0]  [3480/5004]  eta: 0:30:35  lr: 0.000001  loss: 6.9081 (6.9182)  time: 1.1292  data: 0.5683  max mem: 6531\n",
      "Epoch: [0]  [3490/5004]  eta: 0:30:22  lr: 0.000001  loss: 6.9054 (6.9182)  time: 1.1306  data: 0.5746  max mem: 6531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [3500/5004]  eta: 0:30:10  lr: 0.000001  loss: 6.9038 (6.9181)  time: 1.1691  data: 0.6133  max mem: 6531\n",
      "Epoch: [0]  [3510/5004]  eta: 0:29:58  lr: 0.000001  loss: 6.9022 (6.9181)  time: 1.1791  data: 0.6246  max mem: 6531\n",
      "Epoch: [0]  [3520/5004]  eta: 0:29:46  lr: 0.000001  loss: 6.9056 (6.9180)  time: 1.1713  data: 0.6191  max mem: 6531\n",
      "Epoch: [0]  [3530/5004]  eta: 0:29:33  lr: 0.000001  loss: 6.9081 (6.9180)  time: 1.1552  data: 0.6024  max mem: 6531\n",
      "Epoch: [0]  [3540/5004]  eta: 0:29:22  lr: 0.000001  loss: 6.9068 (6.9180)  time: 1.1563  data: 0.6010  max mem: 6531\n",
      "Epoch: [0]  [3550/5004]  eta: 0:29:09  lr: 0.000001  loss: 6.8986 (6.9179)  time: 1.1835  data: 0.6261  max mem: 6531\n",
      "Epoch: [0]  [3560/5004]  eta: 0:28:58  lr: 0.000001  loss: 6.8996 (6.9179)  time: 1.2111  data: 0.6551  max mem: 6531\n",
      "Epoch: [0]  [3570/5004]  eta: 0:28:45  lr: 0.000001  loss: 6.8984 (6.9178)  time: 1.2056  data: 0.6473  max mem: 6531\n",
      "Epoch: [0]  [3580/5004]  eta: 0:28:33  lr: 0.000001  loss: 6.8984 (6.9178)  time: 1.1856  data: 0.6232  max mem: 6531\n",
      "Epoch: [0]  [3590/5004]  eta: 0:28:21  lr: 0.000001  loss: 6.9033 (6.9177)  time: 1.1727  data: 0.6129  max mem: 6531\n",
      "Epoch: [0]  [3600/5004]  eta: 0:28:09  lr: 0.000001  loss: 6.9022 (6.9177)  time: 1.1623  data: 0.6090  max mem: 6531\n",
      "Epoch: [0]  [3610/5004]  eta: 0:27:56  lr: 0.000001  loss: 6.9022 (6.9177)  time: 1.1874  data: 0.6337  max mem: 6531\n",
      "Epoch: [0]  [3620/5004]  eta: 0:27:45  lr: 0.000001  loss: 6.9076 (6.9176)  time: 1.1983  data: 0.6452  max mem: 6531\n",
      "Epoch: [0]  [3630/5004]  eta: 0:27:32  lr: 0.000001  loss: 6.9021 (6.9176)  time: 1.1849  data: 0.6315  max mem: 6531\n",
      "Epoch: [0]  [3640/5004]  eta: 0:27:21  lr: 0.000001  loss: 6.9036 (6.9175)  time: 1.2003  data: 0.6444  max mem: 6531\n",
      "Epoch: [0]  [3650/5004]  eta: 0:27:08  lr: 0.000001  loss: 6.9050 (6.9175)  time: 1.1780  data: 0.6211  max mem: 6531\n",
      "Epoch: [0]  [3660/5004]  eta: 0:26:56  lr: 0.000001  loss: 6.9002 (6.9175)  time: 1.1455  data: 0.5882  max mem: 6531\n",
      "Epoch: [0]  [3670/5004]  eta: 0:26:44  lr: 0.000001  loss: 6.8981 (6.9174)  time: 1.1678  data: 0.6136  max mem: 6531\n",
      "Epoch: [0]  [3680/5004]  eta: 0:26:32  lr: 0.000001  loss: 6.8992 (6.9174)  time: 1.1779  data: 0.6234  max mem: 6531\n",
      "Epoch: [0]  [3690/5004]  eta: 0:26:20  lr: 0.000001  loss: 6.8991 (6.9173)  time: 1.1861  data: 0.6301  max mem: 6531\n",
      "Epoch: [0]  [3700/5004]  eta: 0:26:08  lr: 0.000001  loss: 6.8984 (6.9173)  time: 1.1428  data: 0.5879  max mem: 6531\n",
      "Epoch: [0]  [3710/5004]  eta: 0:25:55  lr: 0.000001  loss: 6.8985 (6.9173)  time: 1.1476  data: 0.5933  max mem: 6531\n",
      "Epoch: [0]  [3720/5004]  eta: 0:25:44  lr: 0.000001  loss: 6.9040 (6.9172)  time: 1.2171  data: 0.6616  max mem: 6531\n",
      "Epoch: [0]  [3730/5004]  eta: 0:25:31  lr: 0.000001  loss: 6.9110 (6.9172)  time: 1.1886  data: 0.6296  max mem: 6531\n",
      "Epoch: [0]  [3740/5004]  eta: 0:25:19  lr: 0.000001  loss: 6.9110 (6.9172)  time: 1.1699  data: 0.6067  max mem: 6531\n",
      "Epoch: [0]  [3750/5004]  eta: 0:25:07  lr: 0.000001  loss: 6.9079 (6.9171)  time: 1.1726  data: 0.6146  max mem: 6531\n",
      "Epoch: [0]  [3760/5004]  eta: 0:24:55  lr: 0.000001  loss: 6.8974 (6.9171)  time: 1.1894  data: 0.6286  max mem: 6531\n",
      "Epoch: [0]  [3770/5004]  eta: 0:24:43  lr: 0.000001  loss: 6.8948 (6.9170)  time: 1.1994  data: 0.6370  max mem: 6531\n",
      "Epoch: [0]  [3780/5004]  eta: 0:24:31  lr: 0.000001  loss: 6.8948 (6.9170)  time: 1.1592  data: 0.6046  max mem: 6531\n",
      "Epoch: [0]  [3790/5004]  eta: 0:24:19  lr: 0.000001  loss: 6.8910 (6.9169)  time: 1.2036  data: 0.6496  max mem: 6531\n",
      "Epoch: [0]  [3800/5004]  eta: 0:24:07  lr: 0.000001  loss: 6.8982 (6.9169)  time: 1.2039  data: 0.6493  max mem: 6531\n",
      "Epoch: [0]  [3810/5004]  eta: 0:23:55  lr: 0.000001  loss: 6.9003 (6.9169)  time: 1.2006  data: 0.6454  max mem: 6531\n",
      "Epoch: [0]  [3820/5004]  eta: 0:23:43  lr: 0.000001  loss: 6.9013 (6.9168)  time: 1.2348  data: 0.6777  max mem: 6531\n",
      "Epoch: [0]  [3830/5004]  eta: 0:23:31  lr: 0.000001  loss: 6.9058 (6.9168)  time: 1.2016  data: 0.6460  max mem: 6531\n",
      "Epoch: [0]  [3840/5004]  eta: 0:23:19  lr: 0.000001  loss: 6.9098 (6.9168)  time: 1.1728  data: 0.6179  max mem: 6531\n",
      "Epoch: [0]  [3850/5004]  eta: 0:23:06  lr: 0.000001  loss: 6.9066 (6.9168)  time: 1.1624  data: 0.6065  max mem: 6531\n",
      "Epoch: [0]  [3860/5004]  eta: 0:22:55  lr: 0.000001  loss: 6.9000 (6.9167)  time: 1.1660  data: 0.6071  max mem: 6531\n",
      "Epoch: [0]  [3870/5004]  eta: 0:22:42  lr: 0.000001  loss: 6.9023 (6.9167)  time: 1.1666  data: 0.6059  max mem: 6531\n",
      "Epoch: [0]  [3880/5004]  eta: 0:22:30  lr: 0.000001  loss: 6.9023 (6.9167)  time: 1.1634  data: 0.6049  max mem: 6531\n",
      "Epoch: [0]  [3890/5004]  eta: 0:22:18  lr: 0.000001  loss: 6.9040 (6.9166)  time: 1.1696  data: 0.6107  max mem: 6531\n",
      "Epoch: [0]  [3900/5004]  eta: 0:22:06  lr: 0.000001  loss: 6.9004 (6.9166)  time: 1.1731  data: 0.6157  max mem: 6531\n",
      "Epoch: [0]  [3910/5004]  eta: 0:21:54  lr: 0.000001  loss: 6.8999 (6.9165)  time: 1.1832  data: 0.6228  max mem: 6531\n",
      "Epoch: [0]  [3920/5004]  eta: 0:21:42  lr: 0.000001  loss: 6.8968 (6.9165)  time: 1.2307  data: 0.6701  max mem: 6531\n",
      "Epoch: [0]  [3930/5004]  eta: 0:21:30  lr: 0.000001  loss: 6.8956 (6.9164)  time: 1.1972  data: 0.6428  max mem: 6531\n",
      "Epoch: [0]  [3940/5004]  eta: 0:21:18  lr: 0.000001  loss: 6.8989 (6.9164)  time: 1.1616  data: 0.6080  max mem: 6531\n",
      "Epoch: [0]  [3950/5004]  eta: 0:21:06  lr: 0.000001  loss: 6.8998 (6.9163)  time: 1.1868  data: 0.6316  max mem: 6531\n",
      "Epoch: [0]  [3960/5004]  eta: 0:20:54  lr: 0.000001  loss: 6.8998 (6.9163)  time: 1.1875  data: 0.6325  max mem: 6531\n",
      "Epoch: [0]  [3970/5004]  eta: 0:20:42  lr: 0.000001  loss: 6.9043 (6.9163)  time: 1.1928  data: 0.6363  max mem: 6531\n",
      "Epoch: [0]  [3980/5004]  eta: 0:20:30  lr: 0.000001  loss: 6.9060 (6.9163)  time: 1.1756  data: 0.6185  max mem: 6531\n",
      "Epoch: [0]  [3990/5004]  eta: 0:20:17  lr: 0.000001  loss: 6.9051 (6.9162)  time: 1.1609  data: 0.6049  max mem: 6531\n",
      "Epoch: [0]  [4000/5004]  eta: 0:20:05  lr: 0.000001  loss: 6.9049 (6.9162)  time: 1.1555  data: 0.6009  max mem: 6531\n",
      "Epoch: [0]  [4010/5004]  eta: 0:19:53  lr: 0.000001  loss: 6.9019 (6.9162)  time: 1.1919  data: 0.6308  max mem: 6531\n",
      "Epoch: [0]  [4020/5004]  eta: 0:19:41  lr: 0.000001  loss: 6.9020 (6.9161)  time: 1.1852  data: 0.6250  max mem: 6531\n",
      "Epoch: [0]  [4030/5004]  eta: 0:19:29  lr: 0.000001  loss: 6.9020 (6.9161)  time: 1.1436  data: 0.5902  max mem: 6531\n",
      "Epoch: [0]  [4040/5004]  eta: 0:19:17  lr: 0.000001  loss: 6.9044 (6.9161)  time: 1.1396  data: 0.5843  max mem: 6531\n",
      "Epoch: [0]  [4050/5004]  eta: 0:19:05  lr: 0.000001  loss: 6.9045 (6.9161)  time: 1.1628  data: 0.6083  max mem: 6531\n",
      "Epoch: [0]  [4060/5004]  eta: 0:18:53  lr: 0.000001  loss: 6.8994 (6.9160)  time: 1.1826  data: 0.6285  max mem: 6531\n",
      "Epoch: [0]  [4070/5004]  eta: 0:18:41  lr: 0.000001  loss: 6.8973 (6.9160)  time: 1.2188  data: 0.6653  max mem: 6531\n",
      "Epoch: [0]  [4080/5004]  eta: 0:18:29  lr: 0.000001  loss: 6.8986 (6.9159)  time: 1.2498  data: 0.6969  max mem: 6531\n",
      "Epoch: [0]  [4090/5004]  eta: 0:18:17  lr: 0.000001  loss: 6.9010 (6.9159)  time: 1.1990  data: 0.6457  max mem: 6531\n",
      "Epoch: [0]  [4100/5004]  eta: 0:18:05  lr: 0.000001  loss: 6.9040 (6.9159)  time: 1.1886  data: 0.6346  max mem: 6531\n",
      "Epoch: [0]  [4110/5004]  eta: 0:17:53  lr: 0.000001  loss: 6.9038 (6.9158)  time: 1.2442  data: 0.6906  max mem: 6531\n",
      "Epoch: [0]  [4120/5004]  eta: 0:17:41  lr: 0.000001  loss: 6.8979 (6.9158)  time: 1.2065  data: 0.6523  max mem: 6531\n",
      "Epoch: [0]  [4130/5004]  eta: 0:17:29  lr: 0.000001  loss: 6.8959 (6.9157)  time: 1.1514  data: 0.5963  max mem: 6531\n",
      "Epoch: [0]  [4140/5004]  eta: 0:17:17  lr: 0.000001  loss: 6.8955 (6.9157)  time: 1.1733  data: 0.6199  max mem: 6531\n",
      "Epoch: [0]  [4150/5004]  eta: 0:17:05  lr: 0.000001  loss: 6.8993 (6.9157)  time: 1.1629  data: 0.6105  max mem: 6531\n",
      "Epoch: [0]  [4160/5004]  eta: 0:16:53  lr: 0.000001  loss: 6.9001 (6.9157)  time: 1.1834  data: 0.6227  max mem: 6531\n",
      "Epoch: [0]  [4170/5004]  eta: 0:16:40  lr: 0.000001  loss: 6.9103 (6.9157)  time: 1.1740  data: 0.6112  max mem: 6531\n",
      "Epoch: [0]  [4180/5004]  eta: 0:16:29  lr: 0.000001  loss: 6.9103 (6.9156)  time: 1.1639  data: 0.6070  max mem: 6531\n",
      "Epoch: [0]  [4190/5004]  eta: 0:16:16  lr: 0.000001  loss: 6.9069 (6.9156)  time: 1.1916  data: 0.6367  max mem: 6531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [4200/5004]  eta: 0:16:05  lr: 0.000001  loss: 6.9035 (6.9156)  time: 1.1720  data: 0.6158  max mem: 6531\n",
      "Epoch: [0]  [4210/5004]  eta: 0:15:52  lr: 0.000001  loss: 6.9011 (6.9156)  time: 1.1650  data: 0.6018  max mem: 6531\n",
      "Epoch: [0]  [4220/5004]  eta: 0:15:41  lr: 0.000001  loss: 6.9034 (6.9155)  time: 1.2030  data: 0.6426  max mem: 6531\n",
      "Epoch: [0]  [4230/5004]  eta: 0:15:28  lr: 0.000001  loss: 6.9035 (6.9155)  time: 1.2297  data: 0.6760  max mem: 6531\n",
      "Epoch: [0]  [4240/5004]  eta: 0:15:17  lr: 0.000001  loss: 6.9044 (6.9155)  time: 1.1891  data: 0.6345  max mem: 6531\n",
      "Epoch: [0]  [4250/5004]  eta: 0:15:04  lr: 0.000001  loss: 6.9042 (6.9154)  time: 1.1616  data: 0.6063  max mem: 6531\n",
      "Epoch: [0]  [4260/5004]  eta: 0:14:53  lr: 0.000001  loss: 6.9036 (6.9154)  time: 1.2022  data: 0.6431  max mem: 6531\n",
      "Epoch: [0]  [4270/5004]  eta: 0:14:40  lr: 0.000001  loss: 6.8983 (6.9153)  time: 1.2164  data: 0.6546  max mem: 6531\n",
      "Epoch: [0]  [4280/5004]  eta: 0:14:29  lr: 0.000001  loss: 6.8952 (6.9153)  time: 1.1943  data: 0.6389  max mem: 6531\n",
      "Epoch: [0]  [4290/5004]  eta: 0:14:16  lr: 0.000001  loss: 6.8981 (6.9153)  time: 1.1705  data: 0.6191  max mem: 6531\n",
      "Epoch: [0]  [4300/5004]  eta: 0:14:04  lr: 0.000001  loss: 6.9047 (6.9152)  time: 1.1698  data: 0.6167  max mem: 6531\n",
      "Epoch: [0]  [4310/5004]  eta: 0:13:52  lr: 0.000001  loss: 6.9018 (6.9152)  time: 1.1802  data: 0.6226  max mem: 6531\n",
      "Epoch: [0]  [4320/5004]  eta: 0:13:40  lr: 0.000001  loss: 6.9018 (6.9152)  time: 1.1709  data: 0.6090  max mem: 6531\n",
      "Epoch: [0]  [4330/5004]  eta: 0:13:28  lr: 0.000001  loss: 6.9032 (6.9151)  time: 1.1926  data: 0.6345  max mem: 6531\n",
      "Epoch: [0]  [4340/5004]  eta: 0:13:16  lr: 0.000001  loss: 6.9032 (6.9151)  time: 1.1741  data: 0.6170  max mem: 6531\n",
      "Epoch: [0]  [4350/5004]  eta: 0:13:04  lr: 0.000001  loss: 6.9051 (6.9151)  time: 1.1475  data: 0.5881  max mem: 6531\n",
      "Epoch: [0]  [4360/5004]  eta: 0:12:52  lr: 0.000001  loss: 6.9037 (6.9151)  time: 1.1694  data: 0.6050  max mem: 6531\n",
      "Epoch: [0]  [4370/5004]  eta: 0:12:40  lr: 0.000001  loss: 6.9073 (6.9150)  time: 1.1884  data: 0.6272  max mem: 6531\n",
      "Epoch: [0]  [4380/5004]  eta: 0:12:28  lr: 0.000001  loss: 6.9006 (6.9150)  time: 1.1847  data: 0.6305  max mem: 6531\n",
      "Epoch: [0]  [4390/5004]  eta: 0:12:16  lr: 0.000001  loss: 6.8986 (6.9150)  time: 1.1706  data: 0.6156  max mem: 6531\n",
      "Epoch: [0]  [4400/5004]  eta: 0:12:04  lr: 0.000001  loss: 6.9012 (6.9149)  time: 1.1700  data: 0.6166  max mem: 6531\n",
      "Epoch: [0]  [4410/5004]  eta: 0:11:52  lr: 0.000001  loss: 6.9080 (6.9149)  time: 1.1746  data: 0.6201  max mem: 6531\n",
      "Epoch: [0]  [4420/5004]  eta: 0:11:40  lr: 0.000001  loss: 6.9066 (6.9149)  time: 1.1880  data: 0.6322  max mem: 6531\n",
      "Epoch: [0]  [4430/5004]  eta: 0:11:28  lr: 0.000001  loss: 6.9032 (6.9149)  time: 1.1712  data: 0.6153  max mem: 6531\n",
      "Epoch: [0]  [4440/5004]  eta: 0:11:16  lr: 0.000001  loss: 6.9042 (6.9149)  time: 1.1617  data: 0.6025  max mem: 6531\n",
      "Epoch: [0]  [4450/5004]  eta: 0:11:04  lr: 0.000001  loss: 6.9046 (6.9148)  time: 1.1765  data: 0.6177  max mem: 6531\n",
      "Epoch: [0]  [4460/5004]  eta: 0:10:52  lr: 0.000001  loss: 6.9025 (6.9148)  time: 1.1605  data: 0.6064  max mem: 6531\n",
      "Epoch: [0]  [4470/5004]  eta: 0:10:40  lr: 0.000001  loss: 6.9022 (6.9148)  time: 1.1977  data: 0.6447  max mem: 6531\n",
      "Epoch: [0]  [4480/5004]  eta: 0:10:28  lr: 0.000001  loss: 6.8993 (6.9147)  time: 1.2217  data: 0.6679  max mem: 6531\n",
      "Epoch: [0]  [4490/5004]  eta: 0:10:16  lr: 0.000001  loss: 6.8942 (6.9147)  time: 1.2001  data: 0.6457  max mem: 6531\n",
      "Epoch: [0]  [4500/5004]  eta: 0:10:04  lr: 0.000001  loss: 6.8999 (6.9147)  time: 1.1861  data: 0.6315  max mem: 6531\n",
      "Epoch: [0]  [4510/5004]  eta: 0:09:52  lr: 0.000001  loss: 6.9045 (6.9147)  time: 1.1719  data: 0.6153  max mem: 6531\n",
      "Epoch: [0]  [4520/5004]  eta: 0:09:40  lr: 0.000001  loss: 6.9016 (6.9146)  time: 1.1811  data: 0.6240  max mem: 6531\n",
      "Epoch: [0]  [4530/5004]  eta: 0:09:28  lr: 0.000001  loss: 6.8928 (6.9146)  time: 1.2074  data: 0.6523  max mem: 6531\n",
      "Epoch: [0]  [4540/5004]  eta: 0:09:16  lr: 0.000001  loss: 6.8948 (6.9145)  time: 1.1962  data: 0.6420  max mem: 6531\n",
      "Epoch: [0]  [4550/5004]  eta: 0:09:04  lr: 0.000001  loss: 6.9009 (6.9145)  time: 1.1803  data: 0.6269  max mem: 6531\n",
      "Epoch: [0]  [4560/5004]  eta: 0:08:52  lr: 0.000001  loss: 6.9013 (6.9145)  time: 1.1978  data: 0.6446  max mem: 6531\n",
      "Epoch: [0]  [4570/5004]  eta: 0:08:40  lr: 0.000001  loss: 6.9035 (6.9144)  time: 1.2030  data: 0.6507  max mem: 6531\n",
      "Epoch: [0]  [4580/5004]  eta: 0:08:28  lr: 0.000001  loss: 6.9058 (6.9144)  time: 1.1899  data: 0.6330  max mem: 6531\n",
      "Epoch: [0]  [4590/5004]  eta: 0:08:16  lr: 0.000001  loss: 6.9013 (6.9144)  time: 1.1824  data: 0.6240  max mem: 6531\n",
      "Epoch: [0]  [4600/5004]  eta: 0:08:04  lr: 0.000001  loss: 6.8998 (6.9144)  time: 1.1775  data: 0.6207  max mem: 6531\n",
      "Epoch: [0]  [4610/5004]  eta: 0:07:52  lr: 0.000001  loss: 6.8957 (6.9143)  time: 1.1727  data: 0.6148  max mem: 6531\n",
      "Epoch: [0]  [4620/5004]  eta: 0:07:40  lr: 0.000001  loss: 6.8953 (6.9143)  time: 1.1844  data: 0.6230  max mem: 6531\n",
      "Epoch: [0]  [4630/5004]  eta: 0:07:28  lr: 0.000001  loss: 6.9000 (6.9142)  time: 1.1893  data: 0.6282  max mem: 6531\n",
      "Epoch: [0]  [4640/5004]  eta: 0:07:16  lr: 0.000001  loss: 6.9045 (6.9142)  time: 1.1790  data: 0.6189  max mem: 6531\n",
      "Epoch: [0]  [4650/5004]  eta: 0:07:04  lr: 0.000001  loss: 6.9049 (6.9142)  time: 1.1732  data: 0.6127  max mem: 6531\n",
      "Epoch: [0]  [4660/5004]  eta: 0:06:52  lr: 0.000001  loss: 6.9047 (6.9142)  time: 1.1914  data: 0.6363  max mem: 6531\n",
      "Epoch: [0]  [4670/5004]  eta: 0:06:40  lr: 0.000001  loss: 6.9025 (6.9141)  time: 1.2370  data: 0.6807  max mem: 6531\n",
      "Epoch: [0]  [4680/5004]  eta: 0:06:28  lr: 0.000001  loss: 6.9014 (6.9141)  time: 1.2361  data: 0.6807  max mem: 6531\n",
      "Epoch: [0]  [4690/5004]  eta: 0:06:16  lr: 0.000001  loss: 6.9014 (6.9141)  time: 1.1976  data: 0.6432  max mem: 6531\n",
      "Epoch: [0]  [4700/5004]  eta: 0:06:04  lr: 0.000001  loss: 6.9052 (6.9141)  time: 1.1767  data: 0.6203  max mem: 6531\n",
      "Epoch: [0]  [4710/5004]  eta: 0:05:52  lr: 0.000001  loss: 6.9052 (6.9141)  time: 1.1716  data: 0.6167  max mem: 6531\n",
      "Epoch: [0]  [4720/5004]  eta: 0:05:40  lr: 0.000001  loss: 6.9002 (6.9140)  time: 1.1897  data: 0.6349  max mem: 6531\n",
      "Epoch: [0]  [4730/5004]  eta: 0:05:28  lr: 0.000001  loss: 6.9002 (6.9140)  time: 1.1818  data: 0.6250  max mem: 6531\n",
      "Epoch: [0]  [4740/5004]  eta: 0:05:16  lr: 0.000001  loss: 6.8998 (6.9140)  time: 1.1736  data: 0.6191  max mem: 6531\n",
      "Epoch: [0]  [4750/5004]  eta: 0:05:04  lr: 0.000001  loss: 6.9027 (6.9140)  time: 1.1730  data: 0.6193  max mem: 6531\n",
      "Epoch: [0]  [4760/5004]  eta: 0:04:52  lr: 0.000001  loss: 6.8979 (6.9139)  time: 1.1653  data: 0.6118  max mem: 6531\n",
      "Epoch: [0]  [4770/5004]  eta: 0:04:40  lr: 0.000001  loss: 6.9013 (6.9139)  time: 1.2035  data: 0.6471  max mem: 6531\n",
      "Epoch: [0]  [4780/5004]  eta: 0:04:28  lr: 0.000001  loss: 6.9073 (6.9139)  time: 1.2346  data: 0.6748  max mem: 6531\n",
      "Epoch: [0]  [4790/5004]  eta: 0:04:16  lr: 0.000001  loss: 6.9073 (6.9139)  time: 1.2062  data: 0.6518  max mem: 6531\n",
      "Epoch: [0]  [4800/5004]  eta: 0:04:04  lr: 0.000001  loss: 6.9019 (6.9138)  time: 1.1694  data: 0.6162  max mem: 6531\n",
      "Epoch: [0]  [4810/5004]  eta: 0:03:52  lr: 0.000001  loss: 6.8992 (6.9138)  time: 1.1604  data: 0.6032  max mem: 6531\n",
      "Epoch: [0]  [4820/5004]  eta: 0:03:40  lr: 0.000001  loss: 6.9016 (6.9138)  time: 1.1738  data: 0.6163  max mem: 6531\n",
      "Epoch: [0]  [4830/5004]  eta: 0:03:28  lr: 0.000001  loss: 6.9055 (6.9138)  time: 1.1683  data: 0.6114  max mem: 6531\n",
      "Epoch: [0]  [4840/5004]  eta: 0:03:16  lr: 0.000001  loss: 6.8993 (6.9137)  time: 1.1847  data: 0.6296  max mem: 6531\n",
      "Epoch: [0]  [4850/5004]  eta: 0:03:04  lr: 0.000001  loss: 6.8952 (6.9137)  time: 1.1893  data: 0.6357  max mem: 6531\n",
      "Epoch: [0]  [4860/5004]  eta: 0:02:52  lr: 0.000001  loss: 6.8952 (6.9136)  time: 1.1738  data: 0.6181  max mem: 6531\n",
      "Epoch: [0]  [4870/5004]  eta: 0:02:40  lr: 0.000001  loss: 6.8929 (6.9136)  time: 1.2108  data: 0.6537  max mem: 6531\n",
      "Epoch: [0]  [4880/5004]  eta: 0:02:28  lr: 0.000001  loss: 6.9005 (6.9136)  time: 1.2196  data: 0.6621  max mem: 6531\n",
      "Epoch: [0]  [4890/5004]  eta: 0:02:16  lr: 0.000001  loss: 6.8976 (6.9135)  time: 1.2330  data: 0.6701  max mem: 6531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [4900/5004]  eta: 0:02:04  lr: 0.000001  loss: 6.8976 (6.9135)  time: 1.2580  data: 0.6926  max mem: 6531\n",
      "Epoch: [0]  [4910/5004]  eta: 0:01:52  lr: 0.000001  loss: 6.8965 (6.9135)  time: 1.2662  data: 0.7077  max mem: 6531\n",
      "Epoch: [0]  [4920/5004]  eta: 0:01:40  lr: 0.000001  loss: 6.9050 (6.9135)  time: 1.2419  data: 0.6857  max mem: 6531\n",
      "Epoch: [0]  [4930/5004]  eta: 0:01:28  lr: 0.000001  loss: 6.9006 (6.9134)  time: 1.2161  data: 0.6621  max mem: 6531\n",
      "Epoch: [0]  [4940/5004]  eta: 0:01:16  lr: 0.000001  loss: 6.8988 (6.9134)  time: 1.1916  data: 0.6410  max mem: 6531\n",
      "Epoch: [0]  [4950/5004]  eta: 0:01:04  lr: 0.000001  loss: 6.8988 (6.9134)  time: 1.1965  data: 0.6476  max mem: 6531\n",
      "Epoch: [0]  [4960/5004]  eta: 0:00:52  lr: 0.000001  loss: 6.8963 (6.9133)  time: 1.1877  data: 0.6407  max mem: 6531\n",
      "Epoch: [0]  [4970/5004]  eta: 0:00:40  lr: 0.000001  loss: 6.8963 (6.9133)  time: 1.1787  data: 0.6260  max mem: 6531\n",
      "Epoch: [0]  [4980/5004]  eta: 0:00:28  lr: 0.000001  loss: 6.8945 (6.9133)  time: 1.2369  data: 0.6803  max mem: 6531\n",
      "Epoch: [0]  [4990/5004]  eta: 0:00:16  lr: 0.000001  loss: 6.8949 (6.9132)  time: 1.2114  data: 0.6571  max mem: 6531\n",
      "Epoch: [0]  [5000/5004]  eta: 0:00:04  lr: 0.000001  loss: 6.8949 (6.9132)  time: 1.1678  data: 0.6135  max mem: 6531\n",
      "Epoch: [0]  [5003/5004]  eta: 0:00:01  lr: 0.000001  loss: 6.8949 (6.9132)  time: 1.0790  data: 0.5286  max mem: 6531\n",
      "Epoch: [0] Total time: 1:39:58 (1.1987 s / it)\n",
      "Averaged stats: lr: 0.000001  loss: 6.8949 (6.9132)\n"
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "train_stats = train_one_epoch(\n",
    "            model, criterion, data_loader_train,\n",
    "            optimizer, device, epoch, loss_scaler,\n",
    "            args.clip_grad, model_ema, mixup_fn,\n",
    "            set_training_mode=args.finetune == ''  # keep in eval mode during finetuning\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27c2fcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler.step(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "95cce6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.output_dir:\n",
    "    checkpoint_paths = [output_dir / 'checkpoint.pth']\n",
    "    for checkpoint_path in checkpoint_paths:\n",
    "        utils.save_on_master({\n",
    "            'model': model_without_ddp.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'lr_scheduler': lr_scheduler.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'model_ema': get_state_dict(model_ema),\n",
    "            'scaler': loss_scaler.state_dict(),\n",
    "            'args': args,\n",
    "        }, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4a88ba51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  [  0/131]  eta: 0:19:00  loss: 6.7376 (6.7376)  acc1: 2.6042 (2.6042)  acc5: 4.6875 (4.6875)  time: 8.7055  data: 8.1211  max mem: 6531\n",
      "Test:  [ 10/131]  eta: 0:04:28  loss: 6.8595 (6.8519)  acc1: 0.0000 (0.4735)  acc5: 0.0000 (1.3494)  time: 2.2185  data: 1.8928  max mem: 6531\n",
      "Test:  [ 20/131]  eta: 0:03:54  loss: 6.8579 (6.8560)  acc1: 0.0000 (0.4092)  acc5: 0.5208 (1.4013)  time: 1.7842  data: 1.4789  max mem: 6531\n",
      "Test:  [ 30/131]  eta: 0:03:13  loss: 6.8882 (6.8773)  acc1: 0.0000 (0.3696)  acc5: 0.2604 (1.1341)  time: 1.7464  data: 1.4391  max mem: 6531\n",
      "Test:  [ 40/131]  eta: 0:03:00  loss: 6.8899 (6.8758)  acc1: 0.0000 (0.3303)  acc5: 0.0000 (0.9909)  time: 1.8458  data: 1.5349  max mem: 6531\n",
      "Test:  [ 50/131]  eta: 0:02:35  loss: 6.8448 (6.8673)  acc1: 0.0000 (0.2859)  acc5: 0.0000 (1.0672)  time: 1.9316  data: 1.6164  max mem: 6531\n",
      "Test:  [ 60/131]  eta: 0:02:16  loss: 6.8422 (6.8655)  acc1: 0.0000 (0.3671)  acc5: 0.7812 (1.2893)  time: 1.7852  data: 1.4639  max mem: 6531\n",
      "Test:  [ 70/131]  eta: 0:01:55  loss: 6.8539 (6.8631)  acc1: 0.0000 (0.4438)  acc5: 0.7812 (1.4891)  time: 1.8037  data: 1.4740  max mem: 6531\n",
      "Test:  [ 80/131]  eta: 0:01:37  loss: 6.8612 (6.8636)  acc1: 0.0000 (0.4212)  acc5: 0.2604 (1.4596)  time: 1.8901  data: 1.5675  max mem: 6531\n",
      "Test:  [ 90/131]  eta: 0:01:16  loss: 6.8436 (6.8621)  acc1: 0.0000 (0.3921)  acc5: 0.2604 (1.3851)  time: 1.7700  data: 1.4583  max mem: 6531\n",
      "Test:  [100/131]  eta: 0:00:58  loss: 6.8571 (6.8645)  acc1: 0.0000 (0.3532)  acc5: 0.2604 (1.3098)  time: 1.7959  data: 1.4869  max mem: 6531\n",
      "Test:  [110/131]  eta: 0:00:38  loss: 6.8652 (6.8646)  acc1: 0.0000 (0.3261)  acc5: 0.0000 (1.2552)  time: 1.7859  data: 1.4748  max mem: 6531\n",
      "Test:  [120/131]  eta: 0:00:20  loss: 6.8652 (6.8640)  acc1: 0.0000 (0.3035)  acc5: 0.5208 (1.2590)  time: 1.7237  data: 1.4118  max mem: 6531\n",
      "Test:  [130/131]  eta: 0:00:01  loss: 6.8152 (6.8537)  acc1: 0.0000 (0.3620)  acc5: 1.5625 (1.5420)  time: 1.6255  data: 1.3281  max mem: 6531\n",
      "Test: Total time: 0:03:57 (1.8150 s / it)\n",
      "* Acc@1 0.362 Acc@5 1.542 loss 6.854\n"
     ]
    }
   ],
   "source": [
    "test_stats = evaluate(data_loader_val, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "72cbb05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 50000 test images: 0.4%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of the network on the {len(dataset_val)} test images: {test_stats['acc1']:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "43f0e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if max_accuracy < test_stats[\"acc1\"]:\n",
    "    max_accuracy = test_stats[\"acc1\"]\n",
    "    if args.output_dir:\n",
    "        checkpoint_paths = [output_dir / 'best_checkpoint.pth']\n",
    "        for checkpoint_path in checkpoint_paths:\n",
    "            utils.save_on_master({\n",
    "                'model': model_without_ddp.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'lr_scheduler': lr_scheduler.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'model_ema': get_state_dict(model_ema),\n",
    "                'scaler': loss_scaler.state_dict(),\n",
    "                'args': args,\n",
    "            }, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9b89252e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max accuracy: 0.36%\n"
     ]
    }
   ],
   "source": [
    "print(f'Max accuracy: {max_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "30644502",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},\n",
    "             **{f'test_{k}': v for k, v in test_stats.items()},\n",
    "             'epoch': epoch,\n",
    "             'n_parameters': n_parameters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "131693cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.output_dir and utils.is_main_process():\n",
    "    with (output_dir / \"log.txt\").open(\"a\") as f:\n",
    "        f.write(json.dumps(log_stats) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f2da60d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 2:02:17\n"
     ]
    }
   ],
   "source": [
    "total_time = time.time() - start_time\n",
    "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "print('Training time {}'.format(total_time_str))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
